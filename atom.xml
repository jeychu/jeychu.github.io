<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>javfa&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-03-15T13:25:09.709Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Javfa</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>为什么一定要用MQ中间件</title>
    <link href="http://yoursite.com/2019/03/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%80%E5%AE%9A%E8%A6%81%E7%94%A8MQ%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    <id>http://yoursite.com/2019/03/15/为什么一定要用MQ中间件/</id>
    <published>2019-03-15T13:14:03.000Z</published>
    <updated>2019-03-15T13:25:09.709Z</updated>
    
    <content type="html"><![CDATA[<p>系统解耦</p><p>异步调用</p><p>流量削峰</p><p>可用性</p><p>稳定性</p><p>一致性</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;系统解耦&lt;/p&gt;
&lt;p&gt;异步调用&lt;/p&gt;
&lt;p&gt;流量削峰&lt;/p&gt;
&lt;p&gt;可用性&lt;/p&gt;
&lt;p&gt;稳定性&lt;/p&gt;
&lt;p&gt;一致性&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Linux性能优化之网络篇</title>
    <link href="http://yoursite.com/2019/03/15/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%AF%87/"/>
    <id>http://yoursite.com/2019/03/15/Linux性能优化之网络篇/</id>
    <published>2019-03-15T04:54:05.000Z</published>
    <updated>2019-03-15T11:55:17.513Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="网络模型">网络模型</span></h1><p>OSI网络模型，开放式系统互联通信参考模型<sup>Open System Interconnection Reference Model</sup>。</p><p>为了解决网络互联中异构设备的兼容性问题，并解耦复杂的网络包处理流程，OSI模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层和物理层等七层，每层负责不同的功能：</p><ul><li>应用层，负责为应用程序提供统一的接口；</li><li>表示层，负责把数据转换成兼容格式；</li><li>会话层，负责维护计算机之间的通信连接；</li><li>传输层，负责为数据加上传输包头，形成数据包；</li><li>网络层，负责数据的路由和转发；</li><li>数据链路层，负责MAC寻址、错误侦测和改错；</li><li>物理层，负责在物理网络中传输数据帧。</li></ul><p>Linux中，使用的是四层模型，即TCP/IP网络模型：</p><ul><li>应用层，负责向用户提供一组应用程序，如HTTP、FTP、DNS等</li><li>传输层，负责端到端的通信，如TCP、UDP等</li><li>网络层，负责网络包的封装、寻址和路由，如IP、ICMP等</li><li>网络接口层，负责网络包在物理网络中的传输，如MAC寻址、错误侦测以及通过网卡传输网络帧等</li></ul><h1><span id="linux网络栈">Linux网络栈</span></h1><p>有了TCP/IP模型后，在进行网络传输时，数据包就会按照协议栈，对上一层发来的数据进行逐层处理；然后封装上该层的协议头，再发送到下一层。</p><h1><span id="linux网络收发流程">Linux网络收发流程</span></h1><h1><span id="性能指标">性能指标</span></h1><ul><li>带宽，表示链路的最大传输速率，单位通常为b/s。</li><li>吞吐量，表示单位事件内成功传输的数据量，单位通常为b/s或则B/s。吞吐量受带宽限制，而吞吐量/带宽，就是该网络的使用率。</li><li>时延，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。</li><li>PPS<sup>Packet Per Second</sup>，表示以网络包为单位的传输速率。通常用来评估网络的转发能力，比如硬件交换机，通常可以达到线性转发（即PPS可以达到或者接近理论最大值）。而基于Linux服务器的转发，则容易受网络包大小的影响。</li><li>此外，还有网络可用性、并发连接数<sup>TCP连接数量</sup>、丢包率、重传率等</li></ul><h1><span id="网络配置">网络配置</span></h1><p>ip a </p><p>ifconfig</p><h1><span id="套接字信息">套接字信息</span></h1><h1><span id="协议栈统计信息">协议栈统计信息</span></h1><h1><span id="网络吞吐和pps">网络吞吐和PPS</span></h1><h1><span id="连通性和时延">连通性和时延</span></h1><h1><span id="c10k">C10K</span></h1><p>C10K问题最早由Dan Kegel于1999年提出。那时的服务器是32位，配置很少的内存（2G）和千兆网卡</p><p>怎么在这样的系统支持并发1万的请求？</p><p>从资源上来说，对2GB内存和千兆网卡的服务器来说，同时处理10000个请求，只要每个请求处理占用不到200KB的内存和100Kbit的网络带宽即可。所以物理资源足够，接下来是软件的问题，特别是网络IO模型问题。</p><h2><span id="io模型优化">IO模型优化</span></h2><p>两种IO事件通知的方式：</p><ul><li>水平触发：只要文件描述符可以非阻塞地执行IO，就会触发通知。应用程序可以随时检查文件描述符的状态，然后再根据状态，进行IO操作。</li><li>边缘触发：只有在文件描述符的状态发生改变时（也就是IO请求到达时），才发送一次通知。这时候，应用程序要尽可能多地执行IO，直到无法继续读写，才可以停止。</li></ul><h1><span id="c1000k">C1000K</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;网络模型&quot;&gt;网络模型&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;OSI网络模型，开放式系统互联通信参考模型&lt;sup&gt;Open System Interconnection Reference Model&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;为了解决网络互联中异构设备的兼容性
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>大型网站技术架构</title>
    <link href="http://yoursite.com/2019/03/14/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2019/03/14/大型网站技术架构/</id>
    <published>2019-03-14T15:04:49.000Z</published>
    <updated>2019-03-14T15:08:40.881Z</updated>
    
    <content type="html"><![CDATA[<p>此篇为读书笔记。</p><h1><span id="概述">概述</span></h1><h2><span id="大型网站架构演化">大型网站架构演化</span></h2><h2><span id="大型网站架构模式">大型网站架构模式</span></h2><h2><span id="大型网站核心架构要素">大型网站核心架构要素</span></h2><h1><span id="架构">架构</span></h1><h2><span id="高性能架构">高性能架构</span></h2><h2><span id="高可用架构">高可用架构</span></h2><h2><span id="伸缩性架构">伸缩性架构</span></h2><h2><span id="可扩展架构">可扩展架构</span></h2><h2><span id="安全架构">安全架构</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;此篇为读书笔记。&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;概述&quot;&gt;概述&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span id=&quot;大型网站架构演化&quot;&gt;大型网站架构演化&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span id=&quot;大型网站架构模式&quot;&gt;大型网站架构模式&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;
      
    
    </summary>
    
    
      <category term="web" scheme="http://yoursite.com/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>TCP状态详解</title>
    <link href="http://yoursite.com/2019/03/12/TCP%E7%8A%B6%E6%80%81%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2019/03/12/TCP状态详解/</id>
    <published>2019-03-12T13:42:31.000Z</published>
    <updated>2019-03-14T03:12:08.776Z</updated>
    
    <content type="html"><![CDATA[<p>LISTENING：侦听来自远方的TCP端口的连接请求。</p><p>服务器端打开一个socket进行监听，状态为LISTEN。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;LISTENING：侦听来自远方的TCP端口的连接请求。&lt;/p&gt;
&lt;p&gt;服务器端打开一个socket进行监听，状态为LISTEN。&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>CDN</title>
    <link href="http://yoursite.com/2019/03/12/CDN/"/>
    <id>http://yoursite.com/2019/03/12/CDN/</id>
    <published>2019-03-12T13:31:55.000Z</published>
    <updated>2019-03-16T06:08:07.239Z</updated>
    
    <content type="html"><![CDATA[<p>CDN ：缓存服务器+智能DNS</p><p>分布式存储 负载均衡 请求重定向 内容管理</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;CDN ：缓存服务器+智能DNS&lt;/p&gt;
&lt;p&gt;分布式存储 负载均衡 请求重定向 内容管理&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Linux性能优化之磁盘篇</title>
    <link href="http://yoursite.com/2019/03/12/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E7%A3%81%E7%9B%98%E7%AF%87/"/>
    <id>http://yoursite.com/2019/03/12/Linux性能优化之磁盘篇/</id>
    <published>2019-03-12T08:19:51.000Z</published>
    <updated>2019-03-16T06:21:09.772Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="linux文件系统是怎么工作的">Linux文件系统是怎么工作的？</span></h1><p>和CPU、内存一样，磁盘和文件系统的管理，也是操作系统最核心的功能。</p><ul><li>磁盘为系统提供了最基本的持久化存储；</li><li>文件系统则在磁盘的基础上，提供了一个用来管理文件的树状结构。</li></ul><h2><span id="索引节点和目录项">索引节点和目录项</span></h2><p>文件系统，本身是对存储设备上的文件进行组织管理的机制。组织方式的不同，就会形成不同的文件系统。</p><blockquote><p>在Linux中，一切皆文件：普通文件和目录、块设备、套接字、管道等都要通过统一的文件系统来管理。</p></blockquote><p>为了方便管理，Linux文件系统为每个文件都分配两个数据结构：</p><ul><li>索引节点<sup>index node</sup>：简称为inode，用来记录文件的元数据，比如inode编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以，索引节点同样占用磁盘空间。</li><li>目录项<sup>dentry</sup>：用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个<strong>内存数据结构</strong>，所以通常也被叫做目录项缓存。</li></ul><p>索引节点是每个文件的唯一标志，而目录项维护的是文件系统的树状结构。</p><p>目录项和索引节点的关系是多对一，即一个文件可以有多个别名。如硬链接。通过硬链接为文件创建别名，就会对应不同的目录项。这些目录项本质上链接到同一个文件，所以，它们的索引节点相同。</p><p>索引节点和目录项记录了文件的元数据和文件之间的目录关系，那文件数据到底又是怎么存储的呢？</p><p>磁盘读写的最小单位是扇区，而一个扇区只有512B的大小，如果每次都读写这么小的单位，效率是很低的。所以，文件系统把连续的扇区组成逻辑块，然后每次都以逻辑块为最小单位，来管理数据。</p><p>常见的逻辑块大小为4KB，也就是由连续的8个扇区组成。</p><p>目录项、索引节点以及文件数据的关系如下图所示：</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552381349393.png" alt="1552381349393"></p><p>需要注意的是：</p><ul><li>目录项本身就是一个内存缓存，而索引节点则是存储在磁盘中的数据。为了协调磁盘和CPU的性能差异，文件内容会被缓存到Cache中，这些索引节点自然也会缓存到内存中，加速文件的访问。</li><li>磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。其中：<ul><li>超级块，存储整个文件系统的状态；</li><li>索引节点区，用来存储索引节点；</li><li>数据块区，则用来存储文件数据。</li></ul></li></ul><h2><span id="虚拟文件系统">虚拟文件系统</span></h2><p>目录项、索引节点、逻辑块以及超级块，构成了Linux文件系统的四大基本要素。</p><p>为了支持各种不同的文件系统，Linux内核在用户进程和文件系统之间，又引入了一个抽象层，也就是虚拟文件系统VFS<sup>Virtual File System</sup>。</p><p>Linux文件系统架构图：</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552382275869.png" alt="1552382275869"></p><p>在VFS之下，Linux支持各种各样的文件系统，如Ext4、XFS、NFS、ZFS。。。</p><p>按照存储位置的不同，这些文件系统可以分为三类：</p><ul><li>基于磁盘的文件系统，也就是把数据直接存储在计算机本地挂载的磁盘中。如：Ext4、XFS、OverlayFS等；</li><li>基于内存的文件系统，也就是虚拟文件系统。这类文件系统，不需要任何磁盘分配存储空间，但会占用内存。如/proc、/sys<sup>主要用于向用户空间导出层次化的内核对象</sup>；</li><li>网络文件系统，也就是用来访问其他计算机数据的文件系统，比如NFS、SMB、iSCSI等。</li></ul><p>这些文件系统，要先挂载到VFS目录树中的某个子目录<sup>称为挂载点</sup>，然后才能访问其中的文件。</p><h2><span id="文件系统io">文件系统IO</span></h2><p>文件读写方式的各种差异，导致IO的分类多种多样。常见的有：</p><ul><li><p>缓冲与非缓冲IO<sup>是否利用标准库缓存</sup>：</p><ul><li>缓冲IO，指利用标准库缓存来加速文件的访问，标准库内部再通过系统调度访问文件；</li><li>非缓冲IO，指直接通过系统调用来访问文件，不再经过标准库缓存。</li></ul><p>无论缓存IO还是非缓冲IO，最终还是要经过系统调用来访问文件。系统调用后，还会通过页缓存，来减少磁盘的IO操作。</p></li><li><p>直接与非直接IO<sup>是否利用操作系统的页缓存</sup>：</p><ul><li>直接IO，指跳过操作系统的页缓存，直接跟文件系统交互来访问文件；</li><li>非直接IO，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘。</li></ul><p>在系统调用中，指定O_DIRECT标志，可以实现直接IO。如果没有设置过，默认是非直接IO。</p><p>直接IO和非直接IO，本质上还是和文件系统交互。如果是在数据库等场景中，还会有跳过文件系统读写磁盘的情况，也就是裸IO。</p></li><li><p>阻塞与非阻塞IO<sup>根据应用程序是否阻塞自身运行</sup>：</p><ul><li>阻塞IO，指应用程序之下IO操作后，如果没有获得响应，就会阻塞当前线程，自然就不能执行其他任务；</li><li>非阻塞IO，是指应用程序执行IO操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过轮询或者事件通知的形式，获取调用的结果。</li></ul><p>如：在访问管道或网络套接字时，设置O_NONBLOCK标志，就表示用非阻塞方式访问；如果不做任何设置，默认的是阻塞访问。</p></li><li><p>同步和异步IO<sup>根据是否等待响应结果</sup>：</p><ul><li>同步IO，指应用程序执行IO操作后，要一直等到整个IO完成后，才能获得IO响应；</li><li>异步IO，指应用程序执行IO操作后，不用等待完成和完成后的响应，而是继续执行就可以。等到这次IO完成后，响应会用事件通知的方式，告诉应用程序。</li></ul><p>如：在操作文件时，如果设置了O_SYNC或O_DSYNC标志，就代表同步IO。</p><p>在访问管道或网络套接字时，设置了O_ASYNC，就代表异步IO。</p></li></ul><h2><span id="如何查看文件系统的性能情况呢">如何查看文件系统的性能情况呢？</span></h2><h3><span id="容量">容量</span></h3><p>df</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552385605875.png" alt="1552385605875"></p><p>索引节点的容量<sup>inode的个数</sup>，是在格式化磁盘时设定好的，一般由格式化工具自动生成。当你发现索引节点空间不足，但磁盘空间充足时，很可能就是过多小文件导致的。</p><h3><span id="缓存">缓存</span></h3><p>/proc/meminfo</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552386039282.png" alt="1552386039282"></p><p>/proc/slabinfo</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552385847934.png" alt="1552385847934"></p><p>slabtop</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552385975568.png" alt="1552385975568"></p><h1><span id="linux磁盘io是怎么工作的">Linux磁盘IO是怎么工作的？</span></h1><h2><span id="磁盘">磁盘</span></h2><p>磁盘是可以持久化存储的设备，根据存储介质的不同，常见磁盘可以分为：</p><ul><li><p>机械磁盘，也称为硬盘驱动器<sup>Hard Disk Driver</sup>，通常缩写为HDD。机械磁盘主要由盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，然后才能访问数据。</p><p>如果是连续IO，不需要磁道寻址，可以获得较好性能。对于随机IO，需要不停地移动磁头来定位数据位置，读写性能会比较差。</p><p>最小读写单位是扇区，一般为512字节。</p></li><li><p>固态磁盘<sup>Solid State Disk</sup>，通常缩写为SSD。由固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续IO，还是随机IO的性能，都比机械磁盘要好很多。</p><p>最小读写单位是页，一般为4KB、8KB等。</p></li></ul><p>无论机械磁盘还是固态磁盘，相同磁盘的随机IO都要比连续IO慢得多，是因为：</p><ul><li>对机械磁盘来说，由于随机IO需要更多的磁头寻道和盘片旋转，它的性能自然要比连续IO慢；</li><li>对固态磁盘来说，虽然它的随机性能比机械硬盘好很多，但同样存在”先擦除再写入”的限制。随机读写会导致大量的垃圾回收，所以它的随机IO的性能比连续IO，还是差了很多。</li><li>连续IO还可以通过预读的方式，来减少IO请求的次数，这也是其性能优异的一个原因。</li></ul><p>按照接口来分类，可以分为：IDE<sup>Integrated Drive Electronics</sup>、SCSI<sup>Small Computer System Interface</sup>、SAS<sup>Serial Attached SCSI</sup>、SATA<sup>Serial ATA</sup>、FC<sup>Fibre Channel</sup>等。</p><p>不同的接口，往往分配不同的设备名称。比如，IDE设备以hd为前缀，SCSI和SATA以sd为前缀。多块同类型的磁盘，按照a、b、c等的字母顺序来编号。</p><p>在Linux中，磁盘是作为一个块设备来管理的，以块为单位读写数据，支持随机读写。</p><p>每个块设备都会被赋予两个设备号，分别是主、次设备号。主设备号用在驱动程序中，用来区分设备类型；次设备号则是用来给多个同类设备编号。</p><h2><span id="通用块层">通用块层</span></h2><p>与VFS类似，为了减少不同块设备的差异带来的影响，Linux通过一个统一的通用块层，来管理各种不同的块设备。</p><p>通用块层，是处在文件系统和磁盘驱动中间的一个块设备抽象层。它主要有两个功能：</p><ul><li>与VFS类似：向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序；</li><li>给文件系统和应用程序发来的IO请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。</li></ul><p>对IO请求排序的过程，就是IO调度。Linux内核支持四种IO调度算法：</p><ul><li>NONE：不做处理，常用于虚拟机中</li><li>NOOP：最简单的IO调度算法。是一个先入先出的队列，只做一些最基本的请求合并，常用于SSD</li><li>CFQ：是现在很多发行版的默认IO调度器，它为每一个进程维护了一个IO调度队列，并按照时间片来均匀分布每个进程的IO请求。</li><li>DeadLine：分别为读、写创建了不同的IO队列，可以提高机械磁盘的吞吐量，并确保达到最终期限（deadline）的请求被优先处理。多用于IO压力比较重的场景，比如事件库等。</li></ul><h2><span id="io栈">IO栈</span></h2><p>Linux存储系统的IO栈，由上到下分为三个层次，分别是文件系统层、通用块层和设备层。这三个IO层的关系如下图所示：</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552547651555.png" alt="1552547651555"></p><p>通过这张IO全景图，我们可以清楚的理解存储系统IO的工作原理：</p><ul><li>文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现。为上层的应用程序提供标准的文件访问接口；对下通过通用块层，来存储和管理磁盘数据；</li><li>通用块层，包括块设备IO队列和IO调度。对文件系统的IO请求进行排队，通过重新排序和请求合并，然后发送给下一级的设备层；</li><li>设备层，包括存储设备和相应的驱动程序，负责最终物理设备的IO操作。</li></ul><h2><span id="磁盘性能指标">磁盘性能指标</span></h2><ul><li>使用率</li><li>饱和度</li><li>IOPS</li><li>吞吐量</li><li>响应时间</li></ul><h2><span id="磁盘io观测">磁盘IO观测</span></h2><p>每块磁盘的使用情况</p><p>iostat</p><p><img src="/2019/03/12/Linux性能优化之磁盘篇/1552623565915.png" alt="1552623565915"></p><p>进程IO观测</p><p>pidstat -d 1</p><h1><span id="调优策略及实践">调优策略及实践</span></h1><p>文件系统性能研究方法：</p><table><thead><tr><th>方法</th><th style="text-align:center">类型</th></tr></thead><tbody><tr><td>磁盘分析</td><td style="text-align:center">观察分析</td></tr><tr><td>延时分析</td><td style="text-align:center">观察分析</td></tr><tr><td>负载特征归纳</td><td style="text-align:center">观察分析、容量规划</td></tr><tr><td>性能监控</td><td style="text-align:center">观察分析、容量规划</td></tr><tr><td>事件跟踪</td><td style="text-align:center">观察分析</td></tr><tr><td>静态性能调优</td><td style="text-align:center">观察分析、容量规划</td></tr><tr><td>缓存调优</td><td style="text-align:center">观察分析、调优</td></tr><tr><td>负载分离</td><td style="text-align:center">调优</td></tr><tr><td>内存文件系统</td><td style="text-align:center">调优</td></tr><tr><td>微型基准测试</td><td style="text-align:center">实验分析</td></tr></tbody></table><p>这些方法可以单独使用，也可以组合使用。</p><p>推荐按顺序使用以下策略：延时分析、性能监控、负载特征归纳、微型基准测试、静态性能调优和事件跟踪。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;linux文件系统是怎么工作的&quot;&gt;Linux文件系统是怎么工作的？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;和CPU、内存一样，磁盘和文件系统的管理，也是操作系统最核心的功能。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;磁盘为系统提供了最基本的持久化存储；&lt;/li&gt;
&lt;li&gt;文件
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>在CentOS7上安装eBPF-tools,bcc和ply</title>
    <link href="http://yoursite.com/2019/03/12/%E5%9C%A8CentOS7%E4%B8%8A%E5%AE%89%E8%A3%85eBPF-tools-bcc%E5%92%8Cply/"/>
    <id>http://yoursite.com/2019/03/12/在CentOS7上安装eBPF-tools-bcc和ply/</id>
    <published>2019-03-12T03:27:49.000Z</published>
    <updated>2019-03-12T04:20:02.760Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>升级内核：</p><p>CentOS7的内核版本是3.x，要安装使用eBPF，bcc和ply，内核版本至少是4.9，所以需要先升级CentOS7的内核。详见<a href="https://jeychu.github.io/2019/03/11/CentOS7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/" target="_blank" rel="noopener">CentOS7升级内核</a>。</p></li><li><p>升级、安装开发工具：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y epel-release</span><br><span class="line">sudo yum update -y</span><br><span class="line">sudo yum groupinstall -y &quot;Development tools&quot;</span><br><span class="line">sudo yum install -y elfutils-libelf-devel iperf cmake3</span><br></pre></td></tr></table></figure></li><li><p>安装LLVM，clang，ply和bcc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/build</span><br><span class="line">cd ~/build</span><br><span class="line">git clone https://github.com/iovisor/ply.git</span><br><span class="line">cd ply</span><br><span class="line">./autogen.sh</span><br><span class="line"> export CFLAGS=-I$&#123;HOME&#125;/build/usr/include</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">curl -LO http://releases.llvm.org/3.9.1/cfe-3.9.1.src.tar.xz</span><br><span class="line">curl -LO http://releases.llvm.org/3.9.1/llvm-3.9.1.src.tar.xz</span><br><span class="line">tar -xf cfe-3.9.1.src.tar.xz</span><br><span class="line">tar -xf llvm-3.9.1.src.tar.xz</span><br><span class="line">mkdir clang-build</span><br><span class="line">mkdir llvm-build</span><br><span class="line"></span><br><span class="line">cd llvm-build</span><br><span class="line">cmake3 -G &quot;Unix Makefiles&quot; -DLLVM_TARGETS_TO_BUILD=&quot;BPF;X86&quot; \</span><br><span class="line">  -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr ../llvm-3.9.1.src</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line"></span><br><span class="line">cd ../clang-build</span><br><span class="line">cmake3 -G &quot;Unix Makefiles&quot; -DLLVM_TARGETS_TO_BUILD=&quot;BPF;X86&quot; \</span><br><span class="line">  -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr ../cfe-3.9.1.src</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">git clone https://github.com/iovisor/bcc.git</span><br><span class="line">mkdir bcc-build</span><br><span class="line">cd bcc-build</span><br><span class="line">cmake3 -G &quot;Unix Makefiles&quot; -DCMAKE_INSTALL_PREFIX=/usr ../bcc</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure></li><li><p>安装完成：</p><p><img src="/2019/03/12/在CentOS7上安装eBPF-tools-bcc和ply/1552362190205.png" alt="1552362190205"></p></li></ol><p>参考文献：</p><p><a href="http://hydandata.org/installing-ebpf-tools-bcc-and-ply-on-centos-7" target="_blank" rel="noopener">Installing eBPF tools, bcc and ply on CentOS 7</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;升级内核：&lt;/p&gt;
&lt;p&gt;CentOS7的内核版本是3.x，要安装使用eBPF，bcc和ply，内核版本至少是4.9，所以需要先升级CentOS7的内核。详见&lt;a href=&quot;https://jeychu.github.io/2019/03/11/Cent
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>systemtap</title>
    <link href="http://yoursite.com/2019/03/11/systemtap/"/>
    <id>http://yoursite.com/2019/03/11/systemtap/</id>
    <published>2019-03-11T09:45:32.000Z</published>
    <updated>2019-03-13T02:02:50.123Z</updated>
    
    <content type="html"><![CDATA[<p>此篇为systemtap的学习笔记，待更。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;此篇为systemtap的学习笔记，待更。。。&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>CentOS7升级内核</title>
    <link href="http://yoursite.com/2019/03/11/CentOS7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/"/>
    <id>http://yoursite.com/2019/03/11/CentOS7升级内核/</id>
    <published>2019-03-11T07:56:06.000Z</published>
    <updated>2019-03-12T04:16:40.991Z</updated>
    
    <content type="html"><![CDATA[<ol><li>当前版本</li></ol><p><img src="/2019/03/11/CentOS7升级内核/1552291068649.png" alt="1552291068649"></p><ol start="2"><li>开始升级：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br></pre></td></tr></table></figure><p><img src="/2019/03/11/CentOS7升级内核/1552291299843.png" alt="1552291299843"></p><p><img src="/2019/03/11/CentOS7升级内核/1552291341907.png" alt="1552291341907"></p><p><img src="/2019/03/11/CentOS7升级内核/1552291401131.png" alt="1552291401131"></p><ol start="3"><li>将升级后的内核作为默认内核，重启机器</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># grub2-set-default 0</span><br><span class="line"># reboot</span><br></pre></td></tr></table></figure><ol start="4"><li>升级后的版本</li></ol><p><img src="/2019/03/11/CentOS7升级内核/1552353122161.png" alt="1552353122161"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;当前版本&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/2019/03/11/CentOS7升级内核/1552291068649.png&quot; alt=&quot;1552291068649&quot;&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;开始升级：&lt;/li&gt;
&lt;/ol
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux性能优化之内存篇</title>
    <link href="http://yoursite.com/2019/03/10/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E5%86%85%E5%AD%98%E7%AF%87/"/>
    <id>http://yoursite.com/2019/03/10/Linux性能优化之内存篇/</id>
    <published>2019-03-10T11:05:56.000Z</published>
    <updated>2019-03-12T08:10:57.857Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#linux内存是怎么工作的">Linux内存是怎么工作的？</a><ul><li><a href="#内存映射">内存映射</a></li><li><a href="#虚拟内存空间分布">虚拟内存空间分布</a></li><li><a href="#内存分配与回收">内存分配与回收</a></li><li><a href="#如何查看内存使用情况">如何查看内存使用情况</a></li></ul></li><li><a href="#buffer和cache">Buffer和Cache</a></li><li><a href="#如何利用系统缓存优化程序的运行效率">如何利用系统缓存优化程序的运行效率</a></li></ul><!-- tocstop --><h1><span id="linux内存是怎么工作的">Linux内存是怎么工作的？</span></h1><p>内存管理是操作系统最核心的功能之一。内存主要用来存储系统和应用程序的指令、数据、缓存等。</p><p>Linux是怎么管理内存的呢？</p><h2><span id="内存映射">内存映射</span></h2><p>物理内存，也称为主存，大多数计算机用的主存都是动态随机访问内存（DRAM）。</p><p>只有内核才可以直接访问物理内存。进程要访问内存时，该怎么办呢？</p><p>Linux内核给每个进程都提供了一个独立的虚拟地址空间，并且这个地址空间是连续的。</p><p>进程可以很方便地访问虚拟内存。</p><p>虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同字长（单个CPU指令可以处理数的最大长度）的处理器，虚拟地址空间的范围也不同。对于常见的32位和64位系统，它们的虚拟地址空间，如下所示：</p><p><img src="/2019/03/10/Linux性能优化之内存篇/1552216929887.png" alt="1552216929887"></p><p>既然每个进程都有一个这么大的地址空间，那么所有进程的虚拟内存加起来，自然要比实际的物理内存大得多。所以，并不是所有的虚拟内存都会分配物理内存，只有哪些实际使用的虚拟内存才分配物理内存，并且分配后的物理内存，是通过内存映射来管理的。</p><p>内存映射，就是将虚拟内存地址映射到物理内存地址。为了完成内存映射，内核为每个进程都维护了一张页表，记录虚拟地址与物理地址的映射关系，如下图所示：</p><p><img src="/2019/03/10/Linux性能优化之内存篇/1552216874797.png" alt="1552216874797"></p><p>页表存储在CPU的内存管理单元MMU中。</p><p>当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</p><p>TLB是MMU中页表的高速缓存。由于进程的虚拟地址空间是独立的，而TLB的访问速度又比MMU快得多，所以，通过减少进程的上下文切换，减少TLB的刷新次数，就可以提高TLB缓存的使用率，进而提高CPU的内存访问性能。</p><p>MMU规定了内存映射的最小单位为页，通常是4KB大小，以页为单位来管理内存。这样，每一次内存映射，都需要关联4KB或4KB整数倍的内存空间。</p><p>页的大小只有4KB，整个页表非常大。比如，32位系统就需要100多万个页表项<sup>4GB/4KB=1048576</sup>，才可以实现整个地址空间的映射。</p><p>为了解决页表项过多的问题，Linux提供了两种机制：</p><ul><li><p><strong>多级页表</strong>：把内存分成区块来管理，将原来的映射关系改成区块索引和区块内的偏移。由于虚拟内存空间通常只用了很少一部分，那么，多级页表就只保持这些使用中的区块，这样就可以大大减少页表的项数。</p><p>Linux用四级页表来管理内存页，如下图所示，虚拟内存被分为5个部分，前4个表项用于选择页，而最后一个索引表示页内偏移。</p><p><img src="/2019/03/10/Linux性能优化之内存篇/1552218344165.png" alt="1552218344165"></p></li><li><p><strong>大页</strong></p><p>指的是比普通页更大的内存块，常见的大小有2MB和1GB。通常用在使用大量内存的进程上，如Oracle、DPDK等</p></li></ul><p>通过以上机制，在页表的映射下，进程就可以通过虚拟地址来访问物理内存了。那么，具体到一个Linux进程中，这些内存又是怎么使用的呢？</p><h2><span id="虚拟内存空间分布">虚拟内存空间分布</span></h2><p>虚拟内存空间的分布情况，以32位系统为例，如下所示：</p><p><img src="/2019/03/10/Linux性能优化之内存篇/1552218920555.png" alt="1552218920555"></p><p>最上方的是内核空间。虽然，每个进程的地址空间都包含了内核空间，但这些内核空间，其实关联的都是相同的物理内存。</p><p>下方的用户空间内存被划分成了多个不同的段。</p><p>从低到高分别是五种不同的内存段：</p><ol><li>只读段，包括代码和常量等；</li><li>数据段，包括全局变量等；</li><li>堆，包括动态分配的内存，从低地址开始向上增长；</li><li>文件映射段，包括动态库、共享内存等，从高地址开始向下增长；</li><li>栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是8MB。</li></ol><p>内存是怎么分配的呢？</p><h2><span id="内存分配与回收">内存分配与回收</span></h2><p>malloc()是C标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即brk()和mmap()。</p><ul><li><p>对于小块内存（小于128K），C标准库使用brk()来分配内存。也就是通过移动堆顶的位置来分配内存。这些内存释放后并不会立刻归还系统，而是被缓存起来，重复使用。</p><p>缓存的方式，可以减少缺页异常的发生，提高内存访问效率。</p><p>但是由于内存没有归还系统，易造成内存碎片。</p></li><li><p>对于大块内存（大于128K），则直接使用内存映射mmap()来分配。也就是在文件映射段找一块空闲内存分配出去。</p><p>由于释放时，直接归还系统，所以每次mmap都会发生缺页异常。</p><p>大量的缺页异常，使内核的管理负担增大。所以malloc只对大块内存使用mmap。</p></li></ul><p><strong>当这两种调用发生后，其实并没有真正分配内存。这些内存，都只是在首次访问时才被分配，也就是通过缺页异常进入内核中，再由内核来分配内存。</strong></p><p>内核使用伙伴系统来管理内存分配。和MMU一样，伙伴系统也是以页为单位进行管理，并且通过相邻块的合并，减少内存碎片化。</p><p>对于比页更小的对象，比如不到1K的时候，内核通过slab分配器来管理这些小内存。</p><p>对于内存来说，如果只分配而不释放，就会造成内存泄漏，甚至会耗尽系统内存。所以，在应用程序用完内存后，还需要调用free()或unmap()，来释放这些不用的内存。</p><p>在发现内存紧张时，系统会通过以下方式回收内存：</p><ul><li><p>回收缓存，比如使用LRU（Least Recently Used）算法，回收最近使用最少的内存页面；</p></li><li><p>回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中。Swap把一块磁盘空间当成内存来用。从内存到磁盘称为换出，从磁盘读取到内存称为换入。</p></li><li><p>杀死进程，通过OOM（Out Of Memory），直接杀死占用大量内存的进程。内核使用oom_score为每个进程的内存使用情况进行评分：</p><ul><li>一个进程消耗的内存越大，oom_score就越大；</li><li>一个进程运行占用的CPU越大，oom_score就越小。</li></ul><p>oom_score越大，越容易被OOM杀死。</p><p>可以通过调整/proc/中进程的oom_adj来调整进程的oom_score。</p><p>oom_adj的范围为[-17, 15]，数值越大，越容易被OOM杀死；-17表示禁止OOM。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo -16 &gt; /proc/$(pidof sshd)/oom_adj</span><br></pre></td></tr></table></figure><p>将sshd进程的oom_adj调小为-16，以使sshd不容易被OOM杀死。</p></li></ul><h2><span id="如何查看内存使用情况">如何查看内存使用情况</span></h2><p>free</p><p><img src="/2019/03/10/Linux性能优化之内存篇/1552275955243.png" alt="1552275955243"></p><p>available不仅包含未使用的内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。</p><p>top</p><p><img src="/2019/03/10/Linux性能优化之内存篇/1552276016601.png" alt="1552276016601"></p><p>下面部分显示了每个进程的内存使用情况：</p><ul><li>VIRT是进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内；</li><li>RES是常驻内存的大小，也就是进程实际使用的物理内存大小，但不包括Swap和共享内存；</li><li>SHR是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等；需要注意的是，SHR并不一定是共享的，程序的代码段、非共享的动态链接库，也都计算在SHR里。</li><li>%MEM是进程使用物理内存占系统总内存的百分比。</li></ul><h1><span id="buffer和cache">Buffer和Cache</span></h1><p><strong>磁盘读写的缓冲为</strong>Buffer</p><p><strong>文件读写的缓存为</strong>Cache</p><p>注意磁盘读写和文件读写的不同：</p><blockquote><p>磁盘是块设备，可以划分分区，在分区之上再创建文件系统，挂载到某个目录，就可以在这个目录中读写文件。</p></blockquote><p>读写文件时，会经过文件系统，由文件系统和磁盘交互；</p><p>读写磁盘或分区时，会跳过文件系统，也就是裸IO。</p><p>二者所用缓存是不同的。</p><p>Buffer和Cache的设计目的，是为了系统的IO性能。它们利用内存，充当起慢速磁盘和快速CPU之间的桥梁，可以加速IO的访问速度。</p><p>Buffer和Cache分别缓存的是对磁盘和文件系统的读写数据。</p><ul><li>从写的角度来说，不仅可以优化磁盘和文件的写入，对应用程序也有好处，应用程序可以在数据真正落盘前，就返回去做其他工作；</li><li>从度的角度来说，不仅可以提高那些频繁访问数据的读取速度，也降低了频繁IO对磁盘的压力。</li></ul><h1><span id="如何利用系统缓存优化程序的运行效率">如何利用系统缓存优化程序的运行效率</span></h1><p>缓存命中率，指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。</p><p>命中率越高，表示使用缓存带来的收益越高，应用程序的性能也就越好。</p><p>实际上，缓存是现在所有高并发系统必需的核心模块，主要作用就是把经常访问的数据（也就是热点数据），提前读入到内存中。以加快应用程序的响应速度。</p><p>缓存分析工具：cachestat和pcstat</p><p>cachestat在CentOS7上的安装详见：<a href="https://jeychu.github.io/2019/03/12/%E5%9C%A8CentOS7%E4%B8%8A%E5%AE%89%E8%A3%85eBPF-tools-bcc%E5%92%8Cply/" target="_blank" rel="noopener">在CentOS7上安装eBPF-tools,bcc和ply</a></p><p>pcstat的安装：</p><ol><li>安装go语言：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wget https://studygolang.com/dl/golang/go1.11.5.linux-amd64.tar.gz</span><br><span class="line">mkdir /opt/go</span><br><span class="line">tar -xvf go1.11.5.linux-amd64.tar.gz -C /opt/go</span><br><span class="line">mkdir /root/gopath</span><br><span class="line">vim /etc/profile</span><br><span class="line">export GOROOT=/opt/go/go</span><br><span class="line">   export PATH=$PATH:$GOROOT/bin</span><br><span class="line">   export GOPATH=/root/gopath</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>​         安装完成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@es gopath]# go version</span><br><span class="line">go version go1.11.5 linux/amd64</span><br></pre></td></tr></table></figure><ol start="2"><li>安装pcstat：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/gopath/golang.org/</span><br><span class="line">cd /root/gopath/golang.org</span><br><span class="line">git clone https://github.com/golang/sys.git</span><br><span class="line">go get github.com/tobert/pcstat/pcstat</span><br><span class="line">export PATH=$PATH:/root/gopath/bin</span><br></pre></td></tr></table></figure><p>​           安装完成：</p><p><img src="/2019/03/10/Linux性能优化之内存篇/1552368584437.png" alt="1552368584437"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#linux内存是怎么工作的&quot;&gt;Linux内存是怎么工作的？&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#内存映射&quot;&gt;内存映射&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#虚拟内存空间分布&quot;&gt;虚拟内存空间分布&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>MySQL的监控</title>
    <link href="http://yoursite.com/2019/03/09/MySQL%E7%9A%84%E7%9B%91%E6%8E%A7/"/>
    <id>http://yoursite.com/2019/03/09/MySQL的监控/</id>
    <published>2019-03-08T18:05:10.000Z</published>
    <updated>2019-03-09T06:17:27.047Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL</p><p>监控哪些内容？</p><ul><li>数据库服务的可用性</li><li>数据库性能</li><li>主从同步的情况</li><li>服务器的资源</li><li></li></ul><p>怎么监控？</p><p>调优</p><p>先找出瓶颈所在，然后针对瓶颈做出优化</p><p>如何找瓶颈？</p><p>利用top ps vmstat iostat netstat /proc/</p><p>然后用perf strace ltrace systemtap 追踪进程 定位函数</p><p>zabbix添加自定义监控项</p><p>写脚本 -&gt; 在agentd.conf中添加UserParameter -&gt; 在server中用zabbix-get测试 -&gt;在web添加item和graph</p><p>故障排查思路：</p><p>网络 DNS解析是否正常 ping延时</p><p>主机</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;MySQL&lt;/p&gt;
&lt;p&gt;监控哪些内容？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据库服务的可用性&lt;/li&gt;
&lt;li&gt;数据库性能&lt;/li&gt;
&lt;li&gt;主从同步的情况&lt;/li&gt;
&lt;li&gt;服务器的资源&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;怎么监控？&lt;/p&gt;
&lt;p&gt;调优&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>The Kernel of Nginx之用好浏览器的缓存</title>
    <link href="http://yoursite.com/2019/03/06/The-Kernel-of-Nginx%E4%B9%8B%E7%94%A8%E5%A5%BD%E6%B5%8F%E8%A7%88%E5%99%A8%E7%9A%84%E7%BC%93%E5%AD%98/"/>
    <id>http://yoursite.com/2019/03/06/The-Kernel-of-Nginx之用好浏览器的缓存/</id>
    <published>2019-03-06T03:02:25.000Z</published>
    <updated>2019-03-08T12:57:26.489Z</updated>
    
    <content type="html"><![CDATA[<p>浏览器的缓存与nginx缓存</p><ul><li><p>浏览器缓存</p><ul><li>优点：<ul><li>使用有效缓存时，没有网络消耗，速度最快</li><li>即使有网络消耗，但对失效缓存使用304响应做到网络流量消耗最小化</li></ul></li><li>缺点：<ul><li>只提升一个用户的体验</li></ul></li></ul></li><li><p>Nginx缓存</p><ul><li>优点<ul><li>提升所有用户的体验</li><li>相比浏览器缓存，有效降低上游服务的负载</li><li>通过304响应减少Nginx与上游服务间的流量消耗</li></ul></li><li>缺点<ul><li>用户仍然保持网络消耗</li></ul></li></ul></li></ul><p>同时使用浏览器和Nginx缓存</p><p>浏览器缓存</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: 浏览器请求</span><br><span class="line">op1=&gt;operation: 有缓存</span><br><span class="line">op2=&gt;operation: 向浏览器请求带If-None_Match</span><br><span class="line">op3=&gt;operation: 向浏览器请求带If-Modified-Since</span><br><span class="line">op4=&gt;operation: 从缓存读取 200（from cache）</span><br><span class="line">op5=&gt;operation: 向web服务器请求</span><br><span class="line">op6=&gt;operation: 请求响应，缓存协商</span><br><span class="line">op7=&gt;operation: 从缓存读取</span><br><span class="line">con1=&gt;condition: 是否过期？</span><br><span class="line">con2=&gt;condition: Etag？</span><br><span class="line">con3=&gt;condition: Last-Modified？</span><br><span class="line">con4=&gt;condition: 200 or 304？</span><br><span class="line">end=&gt;end: 呈现</span><br><span class="line">st-&gt;op1-&gt;con1</span><br><span class="line">con1(no)-&gt;op4-&gt;end</span><br><span class="line">con1(yes)-&gt;con2</span><br><span class="line">con2(yes)-&gt;op2-&gt;con4</span><br><span class="line">con2(no)-&gt;con3</span><br><span class="line">con3(yes)-&gt;op3-&gt;con4</span><br><span class="line">con3(no)-&gt;op5-&gt;op6</span><br><span class="line">con4(yes)-&gt;op6</span><br><span class="line">con4(no)-&gt;op7-&gt;end</span><br><span class="line">op6-&gt;end</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Syntax： etag on|off;</span><br><span class="line">Default: etag on;</span><br><span class="line">Context: http, server, location</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ngx_sprintf(etag-&gt;value.data, <span class="string">"\"%xT-%xO\""</span>,</span><br><span class="line">           r-&gt;headers_out.last_modified_time,</span><br><span class="line">           r-&gt;headers_out.contect_length_n)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;浏览器的缓存与nginx缓存&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;浏览器缓存&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：&lt;ul&gt;
&lt;li&gt;使用有效缓存时，没有网络消耗，速度最快&lt;/li&gt;
&lt;li&gt;即使有网络消耗，但对失效缓存使用304响应做到网络流量消耗最小化&lt;/li&gt;
&lt;/ul&gt;
&lt;/
      
    
    </summary>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Nginx的优化</title>
    <link href="http://yoursite.com/2019/03/06/nginx%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <id>http://yoursite.com/2019/03/06/nginx的优化/</id>
    <published>2019-03-06T02:26:22.000Z</published>
    <updated>2019-03-10T17:26:17.399Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="基本安全优化">基本安全优化</span></h1><h2><span id="隐藏版本信息">隐藏版本信息</span></h2><h2><span id="更改nginx服务的默认用户">更改Nginx服务的默认用户</span></h2><h2><span id="降权启动nginx">降权启动Nginx</span></h2><h1><span id="参数优化nginx服务性能">参数优化Nginx服务性能</span></h1><h2><span id="进程个数-单个进程的最大连接数">进程个数、单个进程的最大连接数</span></h2><h2><span id="绑定cpu">绑定CPU</span></h2><h2><span id="gzip">gzip</span></h2><h2><span id="expires">expires</span></h2><h1><span id="日志的优化">日志的优化</span></h1><h1><span id="防盗链">防盗链</span></h1><h1><span id="防爬虫">防爬虫</span></h1><h1><span id="目录权限优化">目录权限优化</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;基本安全优化&quot;&gt;基本安全优化&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span id=&quot;隐藏版本信息&quot;&gt;隐藏版本信息&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span id=&quot;更改nginx服务的默认用户&quot;&gt;更改Nginx服务的默认用户&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;
      
    
    </summary>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>无之文</title>
    <link href="http://yoursite.com/2019/03/04/%E6%97%A0%E9%A2%98/"/>
    <id>http://yoursite.com/2019/03/04/无题/</id>
    <published>2019-03-03T16:28:27.000Z</published>
    <updated>2019-03-14T11:02:05.734Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>‘无意识流’<sup>自撰</sup>码点字儿，权当消遣、游戏。</p><p>具体写些什么，写出什么，我自己也是不知道的。</p><p>不断填充，每更以时间戳为领。</p></blockquote><!-- toc --><ul><li><a href="#1934">19/3/4</a></li><li><a href="#1935">19/3/5</a></li><li><a href="#1936">19/3/6</a></li><li><a href="#1938">19/3/8</a></li><li><a href="#1939">19/3/9</a></li><li><a href="#19310">19/3/10</a></li><li><a href="#19312">19/3/12</a></li><li><a href="#19313">19/3/13</a></li><li><a href="#19314">19/3/14</a></li></ul><!-- tocstop --><h1><span id="1934">19/3/4</span></h1><p>老夫聊发少年狂，不自量，频思量，要和困滞斗一场<br>人生不如意十八九，又何必，妄自沉，且奋起，争朝夕，人生百年是不枉</p><p>内核源码纷上阵，战得个天昏又地暗<br>人道是，廿一世纪，人工智能日日新，所能之事无限<br>现如今，百业俱兴于互联网<br>信息流转无量，人人都是网中虫<br>码农立功改了世界，创了互联界，人神之间自此有了个第三界</p><p>微信淘宝千百度，淘了个什么，又信了个什么？<br>大小屏幕满城皆是，人人淹没其间。<br>要在屏幕引源流，码农誓要战到深夜，不眠不休。</p><p>王者荣耀坑起来，坑到王者亦非常人也<br>鲁班后羿虽善射，易被珂切<br>项羽是个霸王，本色是喜欢虞姬<br>妲己是个妖女，总想一套秒<br>凯也是个肉，打不死还善单挑<br>典韦疯癫，满场飞奔…</p><p>恩金克思是个宝<br>鲁啊美月协助跑<br>林刘克思做服务<br>韦伯搞网成了王</p><hr><h1><span id="1935">19/3/5</span></h1><p>iHola!</p><p>¿Como estas?</p><p>香尘已隔犹回面<br>居人匹马映林嘶</p><p>新绿小池塘<br>帘动、碎影、斜阳<br>金屋去来 旧时巢燕<br>土花缭绕 前度霉墙<br>绣阁凤帷理丝簧</p><p>天寒水鸟自相依<br>十百为群戏落辉<br>行人过尽都不起<br>忽闻水响一起飞</p><p>携杖来追凉<br>花桥倚胡床<br>船笛参差起<br>池莲自在香</p><hr><h1><span id="1936">19/3/6</span></h1><p>知海无涯<br>海里行<br>无向即无功<br>看四周，都是极似<br>手中罗盘<br>历历晰晰<br>准方向<br>不旁骛<br>自可离海登陆<br>船体牢靠<br>方向笃定<br>定成航海王，掌控自生</p><hr><p>不自怨艾，稳住，都将烟消云散<br>云开日现<br>金晖永在，云遮不显<br>拨云自可见日<br>谁可拨？<br>大风耶？大风起兮云飞扬<br>大风来，尘土混乌云，暗无天日<br>小风耶？和风暖阳，自是佳时<br>小风何来？自来也<br>拨云见日者，非人力<br>人自求福，不自作孽，静待日开，得其光<br>但日总在，不因云遮就无<br>光透云，人依然可得其几许<br>故莫担心，莫贪心，莫失心<br>阴晴才是此间正道<br>阴晴都是那颗太阳</p><hr><h1><span id="1938">19/3/8</span></h1><p>二月二日 三八女节<br>雌雄合一 天地交泰<br>龙飞凤舞 双翔呈瑞<br>元亨利贞 吉吉吉吉</p><hr><h1><span id="1939">19/3/9</span></h1><p>痛通，痛得不欲生，就通了<br>自不量力者，撞的头破血流，心痛通</p><p>太阳照常升起，逝者从未停歇<br>珍惜光阴，涓滴莫弃<br>昨天已不复存在，明天从未到来，唯有今天，才是所有</p><p>乱 清理 有序<br>减 减 减<br>只剩一个 所向披靡</p><p>不家 于外 往西行</p><hr><h1><span id="19310">19/3/10</span></h1><p>喜鹊上下游嬉<br>貔貅口衔红币<br>金蟾门口招财<br>晶洞坐镇玄武<br>金鸡雄立西方</p><p>尼采句，大乱写：</p><p>能飞之人向上飞<br>于不能飞之人看来，<br>愈高愈渺</p><p>凝视深渊，深渊亦然<br>与恶魔斗，慎成恶魔</p><p>每天<br>若不曾起舞<br>即是<br>辜负了生命</p><p>谦逊基于力量<br>傲慢基于无能</p><p>世界弥漫着焦躁不安，因众人皆急于从各自的枷锁中获得解放</p><p>不懂自己才是生命中最难的部分</p><p>曲则全，要曲莫直，曲曲折折，真理渐得显现</p><p>埋怨自己、憎恨他人之时。。。你需要休息了！</p><p>无有音乐，生活是错</p><p>智慧是个女人，她只爱战士——愿你勇敢、无忧、刚强</p><p>明为何而活，自可承受一切，幸与不幸</p><p>受苦之人，没有悲观的权力</p><hr><h1><span id="19312">19/3/12</span></h1><blockquote><p>引子：欲休息，偶翻莎翁十四行诗，译之，或可读？</p></blockquote><blockquote><p>前方高能：催婚催育，歌颂爱情！</p></blockquote><p>// 赞美爱人也</p><p>Shall I compare you to a summer’s day?<br>You are more lovely and more temperate:<br>Rough winds do shake the darling buds of May,<br>And summer’s lease has all too short a date;<br>Sometime too hot the eye of heaven shines,<br>And often is his gold complexion dimm’d<br>And every fair from fair sometime declines,<br>By chance or nature’s changing course untrimm’d:<br>But your eternal summer shall not fade,<br>Nor lose possession of that fair you own,<br>Nor shall Death brag you wand’rest in his shade,<br>When in eternal lines to time you grow’st.<br>So long as men can breathe or eyes can see,<br>So long lives this, and this gives life to you.</p><p>将你比作夏天？<br>你更美好温和：<br>强风摧折五月可爱花蕾，<br>夏之为期也是太过短暂。<br>日光有时太炙，<br>金色时常被霾。<br>美丽总要逝去，<br>不测或是自然。<br>但你常住之夏永不退，<br>你所有之美也将不失。<br>当你在这不朽诗篇中和时间合为一，<br>死神休大言说你在他的阴影里盘桓。<br>只要有人能看能呼吸，<br>此诗长存并予你生命。</p><p>// 谴责单身主义者也</p><p>From fairest creatures we desire increase,<br>That thereby beauty’s rose might never die,<br>But as the riper should by time decrease,<br>His tender heir might bear his memory:<br>But you, contracted to your own bright eyes,<br>Feed your light’s flame with self-substantial fuel,<br>Making a famine where abundance lies,<br>Yourself your foe, to your sweet self too cruel.<br>You that art now the world’s fresh ornament,<br>And only herald to the gaudy spring,<br>Within your own bud buried your content,<br>And, tender churl, make waste in niggarding:<br>Pity the world, or else this glutton be,<br>To eat the world’s due, by the grave and you.</p><p>美好藩息【好为第四声】<br>美瑰不死。<br>黄熟凋零<br>幼子承继。<br>只从你目<br>以己为柴<br>大烧目火。<br>丰地饥馑<br>尔实尔敌<br>残对汝身。<br>世之璀璨<br>春之先使<br>却事埋藏。<br>温柔残暴<br>吝啬浪费。<br>怜悯此世<br>若不怜世<br>实为贪夫<br>世所应得<br>汝墓及汝<br>尽将蚕食</p><hr><h1><span id="19313">19/3/13</span></h1><p>// 赞生育也，生育使美延续</p><p>When forty winters shall besiege your brow,<br>And dig deep trenches in your beauty’s field,<br>Your youth’s proud livery, so gazed on now,<br>Will be a tattered weed of small worth held:<br>Then being asked, where all your beauty lies,<br>Where all the treasure of your lusty days,<br>To say within your own deep-sunken eyes<br>Were an all-eating shame, and thriftless praise.<br>How much more praise deserved your beauty’s use,<br>If you could answer, “This fair child of mine<br>Shall sum my count, and make my old excuse,”<br>Proving his beauty by your succession.<br>This were to be new made when you are old,<br>And see your blood warm when you feel it cold.</p><p>四十个冬天将使你美丽的额头<br>沟壑起伏<br>你的青春华服，众所倾羡<br>也将破烂如杂草毫无价值<br>彼时，若被问：<br>你的美何在？<br>你光辉岁月的珍宝何在？<br>你深陷的眼窝里，<br>只有些能吞噬所有的羞耻和毫无意义的赞美。<br>但如果你能说，我美丽的孩子就是我的总结，<br>宽恕我的老迈，继承我的美<br>如此，你的美应得更多赞誉<br>当你老时，这就是新生<br>当你冷时，这使你热血</p><hr><h1><span id="19314">19/3/14</span></h1><p>世界上只有两种数学书：</p><ul><li>看了第一页，读不下去。。。</li><li>看了第一句，读不下去。。。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;‘无意识流’&lt;sup&gt;自撰&lt;/sup&gt;码点字儿，权当消遣、游戏。&lt;/p&gt;
&lt;p&gt;具体写些什么，写出什么，我自己也是不知道的。&lt;/p&gt;
&lt;p&gt;不断填充，每更以时间戳为领。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Nginx中的位运算</title>
    <link href="http://yoursite.com/2019/03/02/Nginx%E5%92%8C%E4%BD%8D%E8%BF%90%E7%AE%97/"/>
    <id>http://yoursite.com/2019/03/02/Nginx和位运算/</id>
    <published>2019-03-02T10:39:45.000Z</published>
    <updated>2019-03-03T18:01:08.912Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本篇是学习<a href="https://www.jishuwen.com/d/2EGC/zh-hk" target="_blank" rel="noopener">其他博文</a>的笔记，根据自己的理解，做了些增补和简化。</p></blockquote><p>位运算在Nginx的源码处处可见，如</p><ul><li><p>定义指令的类型</p></li><li><p>标记当前请求是否还有未发送完的数据</p></li><li><p>事件模块里用指针的最低位来标记一个事件是否过期</p></li></ul><p>下面分析以下在Nginx中位运算的经典使用场景。</p><h1><span id="经典使用场景">经典使用场景</span></h1><h2><span id="对齐">对齐</span></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// src/core/ngx_config.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ngx_align(d, a)     (((d) + (a - 1)) &amp; ~(a - 1))</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ngx_align_ptr(p, a)                                                    \</span></span><br><span class="line">    (u_char *) (((<span class="keyword">uintptr_t</span>) (p) + ((<span class="keyword">uintptr_t</span>) a - <span class="number">1</span>)) &amp; ~((<span class="keyword">uintptr_t</span>) a - <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>该宏使得d按a对齐<sup>第一个大于等于d的a倍数</sup>，其中a必须是2的幂次。</p><p>此宏就是寻找最小的且大于等于d的a的倍数。</p><p>由于a是2的幂次，因此a的二进制表示为00…1…00这样的形式，即它只有一个1，a-1便是00…01…1这样的形式。</p><p>接着，~(a-1)就会将低n为全部置0，n为a的低位连续0的个数。</p><p>此时，如果再将一个数和~（a-1）进行一次按位与，就能把这个数的低n位都清零（即成为a的倍数）。</p><p>而把这个数的低n位都清零，最多是从这个数减去a-1。</p><p>故而，d+（a-1）在经过和~（a-1）按位与而做了清零操作之后，最多也是减去a-1，也就是说，经过低位清零之后，其值最小是d，这样我们就得到了一个大于等于d，且低n位是0的对齐数，即一个大于等于d的a倍数。且是第一个大于等于d的a的倍数。</p><h2><span id="位图">位图</span></h2><p>位图，用以标记状态，只使用一个比特位来标记事物，从而节约内存，提升性能。</p><p>Nginx在对uri进行转义时，需要判断一个字符是否是一个保留字符，这样的字符需要被转义。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">// src/core/ngx_string.c</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">uint32_t</span>   uri_component[] = &#123;</span><br><span class="line">        <span class="number">0xffffffff</span>, <span class="comment">/* 1111 1111 1111 1111  1111 1111 1111 1111 */</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">/* ?&gt;=&lt; ;:98 7654 3210  /.-, +*)( '&amp;%$ #"!  */</span></span><br><span class="line">        <span class="number">0xfc009fff</span>, <span class="comment">/* 1111 1100 0000 0000  1001 1111 1111 1111 */</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">/* _^]\ [ZYX WVUT SRQP  ONML KJIH GFED CBA@ */</span></span><br><span class="line">        <span class="number">0x78000001</span>, <span class="comment">/* 0111 1000 0000 0000  0000 0000 0000 0001 */</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">/*  ~&#125;| &#123;zyx wvut srqp  onml kjih gfed cba` */</span></span><br><span class="line">        <span class="number">0xb8000001</span>, <span class="comment">/* 1011 1000 0000 0000  0000 0000 0000 0001 */</span></span><br><span class="line"></span><br><span class="line">        <span class="number">0xffffffff</span>, <span class="comment">/* 1111 1111 1111 1111  1111 1111 1111 1111 */</span></span><br><span class="line">        <span class="number">0xffffffff</span>, <span class="comment">/* 1111 1111 1111 1111  1111 1111 1111 1111 */</span></span><br><span class="line">        <span class="number">0xffffffff</span>, <span class="comment">/* 1111 1111 1111 1111  1111 1111 1111 1111 */</span></span><br><span class="line">        <span class="number">0xffffffff</span>  <span class="comment">/* 1111 1111 1111 1111  1111 1111 1111 1111 */</span></span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure><p>如上所示，一个数组组成一个位图，共包含8各数字，每个数字表示32个状态，因此这个位图标识出了256个字符的状态。为0的位表示一个通用字符，不需要转义，为1的位代表该字符需要转义。<br>如何使用这个位图呢？Nginx在遍历uri的时候，通过一条简单的语句来进行判断：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uri_component[ch &gt;&gt; <span class="number">5</span>] &amp; (<span class="number">1</span> &lt;&lt; (ch &amp; <span class="number">0x1f</span>))</span><br></pre></td></tr></table></figure><p>如上所示，ch表示当前字符，ch&gt;&gt;5是对ch右移5位，这起到一个除以32的效果，这一步操作确定了ch在uri_component的第几个数字上；</p><p>ch&amp;0x1f，则是取出ch低5位的值，相当于取模32，这个值表示ch在对应数字上的第几位；</p><p>1&lt;&lt;(ch&amp;0x1f)，将1左移ch在对应数字上的所在位数。将该数和对应数字相与，就可以取出对应数字上与ch相对应位置的bit位。</p><p>如：ch是‘0’（即数字48），它存在于位图的第二个数字上（48&gt;&gt;5=1)，又在这个数字（0xfc009fff）的第16位上，所以它的状态就是0xfc009fff &amp; 0x10000 = 0，所以‘0’是个通用字符，不用对它转义。</p><blockquote><p>位运算技巧：对一个2的幂次的数进行取模或者除操作的时候，可以通过位运算来实现。</p></blockquote><h2><span id="寻找最低位1的位置">寻找最低位1的位置</span></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lowbit</span><span class="params">(<span class="keyword">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x &amp; ~(x - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>~(x-1)使得除了最低位1的那个位置，其他位置和x都是相反的，因此二者进行按位与操作后，结果里只可能有一个1，便是原本x最低位的1。</p><h2><span id="寻找最高位1的位置">寻找最高位1的位置</span></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">size_t</span> bsf(<span class="keyword">size_t</span> input)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">size_t</span> pos;</span><br><span class="line"></span><br><span class="line">    __asm__(<span class="string">"bsfq %1, %0"</span> : <span class="string">"=r"</span> (pos) : <span class="string">"rm"</span> (input));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">size_t bsf(size_t input)</span><br><span class="line">&#123;</span><br><span class="line">    input |= input &gt;&gt; 1;</span><br><span class="line">    input |= input &gt;&gt; 2;</span><br><span class="line">    input |= input &gt;&gt; 4;</span><br><span class="line">    input |= input &gt;&gt; 8;</span><br><span class="line">    input |= input &gt;&gt; 16;</span><br><span class="line">    input |= input &gt;&gt; 32;</span><br><span class="line"></span><br><span class="line">    return input - (input &gt;&gt; 1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="计算1的个数">计算1的个数</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本篇是学习&lt;a href=&quot;https://www.jishuwen.com/d/2EGC/zh-hk&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;其他博文&lt;/a&gt;的笔记，根据自己的理解，做了些增补和简化。&lt;/p&gt;
&lt;/bloc
      
    
    </summary>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>微服务设计</title>
    <link href="http://yoursite.com/2019/02/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1/"/>
    <id>http://yoursite.com/2019/02/28/微服务设计/</id>
    <published>2019-02-28T14:53:03.000Z</published>
    <updated>2019-03-14T09:10:03.907Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="微服务">微服务</span></h1><h1><span id="演化式架构师">演化式架构师</span></h1><h1><span id="如何建模服务">如何建模服务</span></h1><h1><span id="集成">集成</span></h1><h1><span id="分解单块系统">分解单块系统</span></h1><h1><span id="部署">部署</span></h1><blockquote><p>构建什么、如何构建以及如何部署？</p></blockquote><h2><span id="持续集成简介">持续集成简介</span></h2><ul><li>你是否每天签入代码到主线？</li><li>你是否有一组测试来验证修改？</li><li>当构建失败后，团队是否把修复CI当作第一优先级的事情来做？</li></ul><h2><span id="把ci映射到微服务">把CI映射到微服务</span></h2><p>如何在微服务、CI构建及源代码三者之间，建立起合适的映射呢？</p><p>最简单的，把所有东西放在一起。如下所示，一个巨大的代码库，其中包括所有的代码，并且只有一个构建。向该代码库任何一次的代码提交都会触发构建，在构建中运行相关的验证，然后生成多个构建物，所有这些都是在同一个构建中完成。</p><p><img src="/2019/02/28/微服务设计/1552533778038.png" alt="1552533778038"></p><p>这种模式存在很多明显的缺点：</p><p>如果我仅仅修改了用户访问中的一行代码，所有其他的服务都需要解析验证和构建，但实际上它们并不需要重新验证和构建，在这里，我们花费了不必要的时间。</p><p>这种方法的一个变体是保留一个代码库，但是用多个CI分别映射到代码库的不同部分，如下所示：</p><p><img src="/2019/02/28/微服务设计/1552533870065.png" alt="1552533870065"></p><p>这种模式可能是双刃剑：一方面它会简化检出/检入的流程，但另一方面，由于可以很轻松地同时提交对多个服务的修改，从而容易做出将多个服务耦合在一起的修改。</p><p>另外一种模式是，每个微服务都有自己的CI，可以在将该微服务部署到生产环境之前做一个快速的验证，如下所示：</p><p><img src="/2019/02/28/微服务设计/1552533913998.png" alt="1552533913998"></p><h2><span id="构建流水线">构建流水线</span></h2><p>使用构建流水线的标准发布流程：</p><p><img src="/2019/02/28/微服务设计/1552536246615.png" alt="1552536246615"></p><p>在微服务的世界，我们想要保证服务之间可以独立于彼此进行部署，所以每个服务都有自己独立的CI。</p><p>但也有例外：刚启动一个新项目时，在什么都没有的情况之下，要花很多时间来识别服务边界。</p><p>在识别出稳定的边界之前，可以把所有的初始服务都放到一起，只用一个构建。此时，也经常会发生跨服务边界的修改，把所有的服务都放在同一个构建中，可以减轻跨服务修改的代价。</p><p>当服务的API稳定之后，就可以开始把它们移动到各自的构建之中。</p><h2><span id="平台特定的构建物">平台特定的构建物</span></h2><p>大多数技术栈都有相应的构建物类型，同时也有相关的工具来创建和安装这些构建物。如：Ruby有gem，Java有JAR包和WAR包，Python有egg。</p><p>从部署的角度，只有构建物本身通常是不够的。如Python应用程序需要运行在Nginx或Apache中。</p><p>为了部署和启动这些构建物，需要安装和配置一些其他的软件。使用Ansible、SaltStack进行自动化配置管理，可以很好的解决这个问题。</p><h2><span id="操作系统构建物">操作系统构建物</span></h2><p>有一种方法可以避免多种技术栈下的构建物所带来的问题，那就是使用操作系统支持的构建物。如，基于RedHat或者CentOS的系统来收，可以使用RPM；对于Ubuntu，可以使用deb包；对于Windows，使用MSI。</p><h2><span id="定制化镜像">定制化镜像</span></h2><p>创建定制化虚拟机镜像：</p><p><img src="/2019/02/28/微服务设计/1552537789945.png" alt="1552537789945"></p><p>只需要构建一次镜像，然后根据这些镜像启动虚拟机，不需要再花费时间来安装相应的依赖，因为它们已经在镜像中安装好了。</p><p>如果你的核心依赖没有改变，那么新版本的服务就可以继续使用相同的基础镜像。</p><h3><span id="将镜像作为构建物">将镜像作为构建物</span></h3><p>把服务本身也包含在镜像中，这样就把镜像变成了构建物。</p><p>现在当你启动镜像时，服务就已经就绪了。</p><p>就像使用OS特定软件包那样，可以认为这些VM镜像是对不同技术栈的一层抽象。我们不需要关心运行在镜像中的服务所使用的语言是Ruby还是Java，我们唯一关心的就是它是否工作。然后把精力放在镜像创建和部署的自动化上即可。</p><h3><span id="不可变服务器">不可变服务器</span></h3><p>通过把配置都存到版本控制代码中，我们可以自动化重建服务，甚至重建整个环境。</p><p>但如果部署完成之后，有人登陆到机器上修改了一些东西，就会导致机器的实际配置和源代码管理中的配置不再一致，整个问题叫做配置漂移。</p><p>为了避免这个问题，可以禁止对任何运行的服务器做手动修改。</p><p>并且，无论修改多么小，都需要经过构建流水线来创建新的机器。</p><h2><span id="环境">环境</span></h2><p>不同环境中部署的服务是相同的，但是每个环境的用途却不一样。</p><p>从笔记本到UAT，再到生产环境，我们希望前面的环境都能不断地靠近生产环境，这样就可以更快地捕获到由于环境差异导致的问题。</p><p>类生产环境和快速反馈之间需要持续地做权衡。</p><h2><span id="服务配置">服务配置</span></h2><p>不同环境的配置差异，如何在部署流程中对其进行处理呢？</p><p>可以对每个环境创建不同的构建物，并把配置内建在该构建物中。</p><p>更好的方法是：只创建一个构建物，并将配置单独管理。</p><p>每个环境一个属性文件。</p><p>应对大量微服务时，这是个很好的方法，即使用专用系统来提供配置。</p><h2><span id="服务与主机之间的映射">服务与主机之间的映射</span></h2><h3><span id="单主机多服务">单主机多服务</span></h3><h3><span id="应用程序容器">应用程序容器</span></h3><h3><span id="每个主机一个服务">每个主机一个服务</span></h3><p><img src="/2019/02/28/微服务设计/1552544268022.png" alt="1552544268022"></p><h3><span id="平台即服务">平台即服务</span></h3><h2><span id="自动化">自动化</span></h2><h2><span id="从物理机到虚拟机">从物理机到虚拟机</span></h2><h2><span id="一个部署接口">一个部署接口</span></h2><p>不管用于部署的底层平台和构建物是什么，使用统一接口来部署给定的服务都是很关键的。</p><p>在很多场景下，都有触发部署的需求，从本地开发测试到生产环境部署。这些不同环境的部署机制应该尽量相似。</p><p>参数化的命令行调用是触发任何部署最合理的方式。可以使用CI工具或手动键入来触发脚本的调用。</p><p>部署脚本需要三个参数：</p><ul><li>部署物是什么？微服务的名字</li><li>把该微服务部署到哪个环境之中？</li><li>该微服务的版本信息</li></ul><p>假设，我们已经创建了一个这样的部署脚本。</p><p>在本地开发时，我们键入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deploy artifact=catalog environment=local version=local</span><br></pre></td></tr></table></figure><p>代码一旦提交，CI进行一次构建，生成一个新的构建物，其编号为b456。这个值会在整个流水线中传递。到了测试阶段，CI会执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deplog artifact=catalog environmet=ci version=b456</span><br></pre></td></tr></table></figure><p>环境定义：</p><h1><span id="测试">测试</span></h1><h1><span id="监控">监控</span></h1><h1><span id="安全">安全</span></h1><h1><span id="康威定律和系统设计">康威定律和系统设计</span></h1><h1><span id="规模化微服务">规模化微服务</span></h1><p>故障无处不在</p><p>何为太多</p><p>功能降级</p><p>架构安全</p><p>反脆弱</p><p>幂等</p><p>扩展</p><p>缓存</p><p>自动伸缩</p><p>CAP</p><p>服务发现</p><p>动态服务注册</p><p>文档服务</p><p>自描述</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;微服务&quot;&gt;微服务&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;span id=&quot;演化式架构师&quot;&gt;演化式架构师&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;span id=&quot;如何建模服务&quot;&gt;如何建模服务&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;span id=&quot;集成&quot;&gt;集成&lt;/span
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>JavaScript In A Nutshell</title>
    <link href="http://yoursite.com/2019/02/26/JavaScript-In-A-Nutshell/"/>
    <id>http://yoursite.com/2019/02/26/JavaScript-In-A-Nutshell/</id>
    <published>2019-02-25T17:49:28.000Z</published>
    <updated>2019-03-02T07:54:16.741Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="基础">基础</span></h1><h2><span id="运行时页面构建过程">运行时页面构建过程</span></h2><h3><span id="生命周期概览">生命周期概览</span></h3><p><img src="/2019/02/26/JavaScript-In-A-Nutshell/1551510836738.png" alt="1551510836738"></p><p>客户端Web应用的周期从用户指定某个网站地址开始，由两个步骤组成：<strong>页面构建和事件处理</strong>。</p><p>来个例子，这个例子展示：每当用户移动鼠标或单击页面就会显示一条消息。</p><p>以下是代码：</p><p><img src="/2019/02/26/JavaScript-In-A-Nutshell/1551511209573.png" alt="1551511209573"></p><p>以下是运行和交互结果：</p><p><img src="/2019/02/26/JavaScript-In-A-Nutshell/1551512582730.png" alt="1551512582730"></p><h3><span id="页面构建阶段">页面构建阶段</span></h3><p>该阶段的目标是建立web应用的UI，主要包括两个步骤：</p><ul><li>解析HTML代码并构建文档对象模型（DOM）；</li><li>执行JavaScript代码。</li></ul><p><img src="/2019/02/26/JavaScript-In-A-Nutshell/1551512933518.png" alt="1551512933518"></p><p><img src="/2019/02/26/JavaScript-In-A-Nutshell/1551513184204.png" alt="1551513184204"></p><h3><span id="事件处理">事件处理</span></h3><h1><span id="理解函数">理解函数</span></h1><p>定义与参数</p><p>理解函数调用</p><p>闭包和作用域</p><p>生成器和promise</p><h1><span id="钻研对象">钻研对象</span></h1><p>面向对象与原型</p><p>控制对象的访问</p><p>处理集合</p><p>正则表达式</p><p>代码模式化</p><h1><span id="洞悉浏览器">洞悉浏览器</span></h1><p>DOM操作</p><p>事件</p><p>跨浏览器的开发技巧</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;基础&quot;&gt;基础&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span id=&quot;运行时页面构建过程&quot;&gt;运行时页面构建过程&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span id=&quot;生命周期概览&quot;&gt;生命周期概览&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2019/02/
      
    
    </summary>
    
    
      <category term="Web" scheme="http://yoursite.com/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>Nginx的配置</title>
    <link href="http://yoursite.com/2019/02/21/Nginx%E7%9A%84%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2019/02/21/Nginx的配置/</id>
    <published>2019-02-21T15:21:21.000Z</published>
    <updated>2019-02-24T12:50:13.731Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="运行中的nginx进程间的关系">运行中的Nginx进程间的关系</span></h1><p>在正式提供服务的产品环境中，部署Nginx时都是使用一个master进程来管理多个worker进程，一般情况下，worker进程的数量与服务器上的CPU核心数相等。每一个worker进程都时繁忙的，它们在真正地提供互联网服务，master进程则很“清闲”，只负责监控管理worker进程。worker之间通过共享内存、原子操作等一些进程间通信机制来实现负载均衡等功能。</p><p>Nginx是支持单进程（master进程）提供服务的，那么为什么产品环境下要按照master、worker方式配置同时启动多个进程呢？这样做的好处主要有一下两点：</p><ul><li>由于master进程不会对用户请求提供服务，只用于管理真正提供服务的worker进程，所以master进程可以是唯一的，它仅专注于自己的纯管理工作，为管理员提供命令行服务，包括诸如启动服务、停止服务、重新配置文件、平滑升级程序等。master进程需要拥有较大的权限，例如，通常会使用root用户启动master进程。worker进程的权限要小于或者等于master进程，这样master进程才可以完全地管理worker进程。当任意一个worker进程出现错误从而导致coredump时，master进程会立刻启动新的worker进程继续服务。</li><li>多个worker进程处理互联网请求不但可以提高服务的健壮性，最重要的是，这样可以充分利用现在常见的SMP多核架构，从而实现微观上真正的多核并发处理。为什么要把worker进程数量设置得跟CPU核心数量一致呢？对于Nginx，一个worker进程可以同时处理的请求数只受限于内存大小，而且在架构上，<strong>不同的worker进程之间处理并发请求时几乎没有同步锁的限制</strong>，worker进程通常不会进入睡眠状态，因此，当Nginx上的进程数与CPU核心数相等时（最好每一个worker进程都绑定特定的CPU核心【使用taskset命令来设置进程的CPU亲和性（affinity），将进程绑定到某个或某组CPU核心上】），进程间的切换的代价是最小的。</li></ul><h1><span id="nginx服务的基本配置">Nginx服务的基本配置</span></h1><h2><span id="用于调试进程和定位问题的配置项">用于调试进程和定位问题的配置项</span></h2><ol><li><p>是否以守护进程方式运行Nginx</p><p>语法：daemon on|off;</p><p>默认：daemon on;</p><p>关闭守护进程的模式，方便使用gdb跟踪调试Nginx，在研究Nginx架构时很有用。</p></li><li><p>是否以master/worker方式工作</p><p>语法：master_process on | off;</p><p>默认：master_process on;</p><p>如果用off关闭了master_process方式，就不会fork出worker子进程来处理请求，而是用master进程自身来处理请求。</p></li><li><p>error日志的位置</p><p>语法：error_log /path/file level;</p><p>默认：error_log logs/error.log error;</p><p>error日志是定位Nginx问题的最佳工具，我们可以根据自己的需求妥善设置error日志的路径和级别。<br>/path/file可以是：</p><ul><li>一个具体的文件，例如，默认情况下是logs/error.log文件，最好将它放到一个磁盘空间足够大的位置；</li><li>也可以是/dev/null，这也是关闭error日志的唯一方法；</li><li><p>也可以是stderr，将日志输出到标准错误文件中；</p><p>level是日志的输出级别，取值范围是debug、info、notice、warn、error、crit、alert、emerg，从左到右级别依次增大。当设定一个级别时，大于或者等于该级别的日志都会输出到/path/file文件中，小于该级别的日志则不会输出。</p><p>如果日志级别设定到debug，必须在configure时加入–with-debug配置项。</p></li></ul></li><li><p>是否处理几个特殊的调试点</p><p>语法：debug_points [stop|abort]</p><p>这个配置项也是用来帮助用户跟踪调试Nginx的。Nginx在一些关键的错误逻辑中设置了调试点。如果设置了debug_points为stop，那么Nginx的代码执行到这些调试点时就会发出SIGSTOP信号以用于调试。如果设置为abort，则会产生一个coredump文件，可以使用gdb来查看Nginx当时的各种信息。</p></li><li><p>仅对指定的客户端输出debug级别的日志</p><p>语法：debug_connection [IP|CIDR]</p><p>这个配置项实际上属于事件类配置，因此，它必须放在events {…}中才有效。</p><p>对来自于指定IP地址的请求才会输出debug级别的日志，其他请求仍然沿用error_log中配置的日志级别。</p></li><li><p>限制coredump核心转储文件的大小</p><p>语法：worker_rlimit_core size;</p><p>在Linux系统中，当进程发生错误或收到信号而终止时，系统会将进程执行时的内存内容写入一个文件，以作为调试只用，这就是所谓的核心转储（core dumps）.</p></li><li><p>指定coredump文件生成目录</p><p>语法：working_directory path;</p></li></ol><h2><span id="正常运行的配置项">正常运行的配置项</span></h2><ol><li><p>定义环境变量</p><p>语法：env VAR|VAR=VALUE;</p><p>这个配置项可以让用户直接设置操作系统上的环境变量。</p></li><li><p>嵌入其他配置文件</p><p>语法：include /path/file;</p></li><li><p>pid文件的路径</p><p>语法：pid /path/file;</p><p>默认：pid logs/nginx.pid;</p></li><li><p>Nginx worker进程运行的用户和用户组</p><p>语法：user username [groupname];</p><p>默认：user nobody nodoby;</p></li><li><p>指定Nginx worker进程可以打开的最大句柄描述符个数</p><p>语法：worker_rlimit_nofile limit;</p></li><li><p>限制信号队列</p><p>语法：worker_rlimit_sigpending limit;</p><p>设置每个用户发往Nginx的信号队列的大小。也就是说，当某个用户的信号队列满了，这个用户再发送的信号量就会被丢掉。</p></li></ol><h2><span id="优化性能的配置项">优化性能的配置项</span></h2><ol><li><p>Nginx worker进程个数</p><p>语法：worker_processes number;</p><p>默认：worker_processes 1;</p></li><li><p>绑定Nginx worker进程到指定的CPU内核</p><p>语法：worker_cpu_affinity cpumask [cpumask…]</p><p>例如，如果有4个CPU内核，可以进行如下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">worker_processes 4;</span><br><span class="line">worker_cpu_affinity 1000 0100 0010 0001;</span><br></pre></td></tr></table></figure></li><li><p>SSL硬件加速</p><p>语法：ssl_engine device;</p><p>如果服务器上有ssl硬件加速设备，那么就可以进行配置以加快SSL协议的处理速度。</p></li><li><p>系统调用gettimeofday的执行频率</p><p>语法：timer_resolution t;</p><p>默认情况下，每次内核的事件调用（如epoll、select、poll、kqueue等）返回时，都会执行一次gettimeofday，实现用内核的时钟来更新Nginx中的缓存时钟。</p><p>在早期的内核中，gettimeofday的执行代价不小，因为中间有一次内核态到用户态的内存复制。需要降低gettimeofday的调用频率时，可以使用该配置项，表示至少每t秒才调用一次。</p><p>但在目前的大多数内核中，gettimeofday只是一次vsyscall，仅仅是对共享内存页中的数据做访问，并不是通常的系统调用，代价不大，一般不必使用这个配置。</p></li><li><p>Nginx worker进程优先级设置</p><p>语法：worker_priority nice;</p><p>默认：worker_pricrity 0;</p><p>当有多个进程处于可执行状态时，系统将按照所有进程的优先级来决定本次内核选择哪一个进程执行。</p><p>进程所分配的时间片大小也与进程优先级相关，优先级越高，进程分配到的时间片也就越大。</p><p>（在默认配置下，最小的时间片时5ms，最大的时间片则有800ms。）</p><p>这样，优先级高的进程会占有更多的系统资源。</p></li></ol><h2><span id="事件类配置项">事件类配置项</span></h2><ol><li><p>是否打开accept锁</p><p>语法：accept_mutex [on|off];</p><p>默认：accept_mutex on;</p><p>accept_mutex是Nginx的负载均衡锁。</p><p>这把锁可以让多个worker进程轮流地、序列化地与新的客户端建立TCP连接。</p><p>当某个worker进程建立的连接数量达到worker_connections配置的最大连接数的7/8时，会大大地减小该worker进程试图建立新TCP连接的机会，以此实现所有的worker进程之上处理的客户端请求数尽量接近。</p><p>如果关闭它，那么建立TCP连接的耗时会更短，但worker进程之间的负载会非常不均衡。不建议关闭它。</p></li><li><p>lock文件的路径</p><p>语法：lock_file path/file;</p><p>默认：lock_file logs/nginx.lock;</p><p>accept_mutex为off时，此配置完全不生效。</p><p>accept_mutex为on是，若由于编译程序、操作系统导致Nginx不支持原子锁，这时会用文件锁来实现accecpt锁，此时lock_file所指定的lock文件才会生效。</p><blockquote><p><strong>文件锁</strong>：在多任务操作系统中，如果一个进程尝试对正在被其他进程读取的文件进行写操作，可能会导致正在进行读操作的进程读取到一些被破坏或者不完整的数据；如果两个进程并发对同一个文件进行写操作，可能会导致该文件遭到破坏。因此，为了避免发生这种问题，必须要采用某种机制来<strong>解决多个进程并发访问同一个文件时所面临的同步问题</strong>，由此而产生了文件加锁方面的技术。</p><p>Linux支持的文件锁主要包括劝告锁（advisory lock）和强制锁（mandatory lock）这两种。此外，Linux中还引入了两种强制锁的变种形式：共享模式强制锁（share-mode mandatory lock）和租借锁（lease）。</p></blockquote></li><li><p>使用accept锁后到真正建立连接之间的延迟时间</p><p>语法：accept_mutex_delay Nms;</p><p>默认：accept_mutex_delay 500ms;</p><p>在使用accept锁后，同一时间只有一个worker进程能够取到accept锁。这个锁不是阻塞锁，如果取不到会立刻返回。如果有一个worker进程试图取锁而未得，它至少要等该配置项所定义的时间间隔后才能再次试图取锁。</p></li><li><p>批量建立新连接</p><p>语法：multi_accept [on|off];</p><p>默认：multi_accept off;</p><p>当事件模型通知有新连接时，尽可能地对本次调度中客户端发起的所有TCP请求都建立连接。</p></li><li><p>选择事件模型</p><p>语法：use [kqueue|rtsig|epoll|/dev/poll|select|poll|eventport];</p><p>默认：Nginx会自动使用最合适的事件模型。</p><p>在Linux系统中，epoll性能是最高的。</p></li><li><p>每个worker的最大连接数</p><p>语法：worker_connections number;</p><p>定义每个worker进程可以同时处理的最大连接数。</p></li></ol><h1><span id="使用http核心模块配置一个静态web服务器">使用HTTP核心模块配置一个静态Web服务器</span></h1>]]></content>
    
    <summary type="html">
    
      Nginx的配置详解
    
    </summary>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Web性能指南</title>
    <link href="http://yoursite.com/2019/02/21/Web%E6%80%A7%E8%83%BD%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2019/02/21/Web性能基础/</id>
    <published>2019-02-21T02:54:57.000Z</published>
    <updated>2019-03-16T13:30:49.772Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="网络技术概览">网络技术概览</span></h1><h2><span id="延迟与带宽">延迟与带宽</span></h2><p>速度是关键</p><p>WPO（Web Performance Optimization）产业从无到有，快速增长，充分说明用户越来越重视速度方面的用户体验。</p><p>业绩证实：</p><ul><li>网站越快，用户的黏性越高</li><li>网站越快，用户忠诚度更高</li><li>网站越快，用户转化率越高</li></ul><p>延迟和带宽：</p><ul><li><p>延迟：分组从信息源发送到目的地所需的时间</p></li><li><p>带宽：逻辑或物理通信路径最大的吞吐量</p></li></ul><p>延迟的构成：</p><ul><li>传播延迟<br>消息从发送端到接收端需要的时间，是信号传播距离和速度的函数</li><li>传输延迟<br>把消息中的所有比特转移到链路中需要的时间，是消息长度和链路速率的函数</li><li>处理延迟<br>处理分组首部、检查位错误及确定分组目标所需的时间</li><li>排队延迟<br>到来的分组排队等待处理的时间</li></ul><blockquote><p>在软件交互中，哪怕100-200ms左右的延迟，大多数人都会感觉到‘拖拉’；如果超过了300ms的门槛，就会说“反应迟钝”。</p></blockquote><h2><span id="tcp">TCP</span></h2><p>TCP/IP，是由Vint Cerf和Bob Khan在他们1974年的论文<a href="https://www.cs.princeton.edu/courses/archive/fall06/cos561/papers/cerf74.pdf" target="_blank" rel="noopener">“A Protocol for Packet Network Intercommunication”</a>中首次提出。</p><blockquote><p>TCP/IP V4：</p><p><a href="https://www.rfc-editor.org/rfc/rfc791.txt" target="_blank" rel="noopener">RFC 791- Internet Protocol</a>;</p><p><a href="https://www.rfc-editor.org/rfc/rfc793.txt" target="_blank" rel="noopener">RFC 793 - Transmission Control Protocol</a>.</p></blockquote><p>TCP负责在不可靠的传输信道上提供可靠的传输抽象层，向应用层隐藏了大多数网络通信的复杂细节，比如丢包重发、按序发送、拥塞控制及避免、数据完整等等。</p><p>TCP专门为精确传送做了优化，但并未过多顾及时间。</p><p>现实中，几乎所有的HTTP流量都是通过TCP传送的。</p><p>因此，理解TCP的核心机制是优化web体验所必需的基础。</p><h3><span id="三次握手">三次握手</span></h3><p><img src="/2019/02/21/Web性能基础/1552725463782.png" alt="1552725463782"></p><p>所有的TCP连接一开始都要经过三次握手。</p><p>在两端交换数据之前，就起始序列号达成一致。</p><p>序列号由两端随机生成。</p><p>三次握手后，两端就可以通信了。客户端可以在发送ACK之后，立即发送数据，而服务器必须等接收到ACK之后才能发送数据。</p><p>如上图，三次握手至少就花了56ms。</p><p>三次握手带来的延迟使得每创建一个新TCP连接都要付出很大代价。</p><p>重用连接，可以极大提高TCP应用的性能。</p><p><a href="https://www.rfc-editor.org/rfc/rfc7413.txt" target="_blank" rel="noopener">TCP Fast Open</a>：致力于减少新建TCP连接带来的性能损失。</p><p>经过流量分析和网络模拟，谷歌研究人员发现TFO平均可以降低HTTP事务网络延迟15%、整个页面加载时间10%以上。</p><h3><span id="拥塞预防及控制">拥塞预防及控制</span></h3><h4><span id="流量控制">流量控制</span></h4><p>是一种预防发送端向接收端过多发送数据的机制。</p><p>若不做预防，接收端可能因为忙碌、负载过重或缓冲区而无法处理。</p><p>该机制为：TCP连接的每一方都要通告自己的接收窗口<sup>rwnd，即接收数据缓冲区</sup>的大小。</p><p><img src="/2019/02/21/Web性能基础/1552726988500.png" alt="1552726988500"></p><p>第一次建立连接时，两端都会使用自身系统的默认设置来发送rwnd。</p><p>如果其中一端跟不上数据传输，那它可以向发送端通告一个较小的窗口。假如窗口为零，则表示应用层必须先清空缓冲区，才能再接收剩余数据。</p><p>这个过程贯穿于每个TCP连接的整个生命周期：每个ACK分组都会携带相应的最新rwnd值，以便两端动态调整数据流速，适应两端的容量和处理能力。</p><p>窗口缩放：</p><p>最初的TCP规范设定了窗口的最大值为2<sup>16</sup>即65545字节。RFC 1323提供了TCP窗口缩放的选项，可以把窗口大小由65535字节提高到1G字节。在Linux中可以通过如下命令检查和启用窗口缩放选项：</p><p><code>sysctl net.ipv4.tcp_window_scaling</code></p><p><code>sysctl -w net.ipv4.tcp_window_scaling=1</code></p><h4><span id="慢启动">慢启动</span></h4><p>发送端和接收端在连接建立之初，谁也不知道可用带宽是多少，因此需要一个机制，估算出双方的可用带宽，并根据网络中不断变化的条件动态改变传输速度。</p><p><img src="/2019/02/21/Web性能基础/1552727986717.png" alt="1552727986717"></p><p>如上所示，拥塞窗口的初始值为4个TCP报文段。</p><blockquote><p>TCP报文段的大小即MSS<sup>Max Segment Size</sup>的计算：</p><p>MSS=MTU-sizeof(TCP heder)-sizeof(IP header)</p><p>对于以太网：MTU=1500bytes 故：MSS=1500-20-20=1460bytes</p><p>对于Internet：MTU=576bytes 故：MSS=576-20-20=536bytes</p></blockquote><blockquote><p>MSS的协商确定：</p><p>MSS值只会出现在SYN报文中，即SYN=1时，才会有MSS字段值。当客户端想要以TCP方式从服务器端下载数据时，</p><p>（1）首先客户端会发送一个SYN请求报文，这个SYN报文的“选项”字段中会有MSS值（MSS = MUT - IP首部长度 - TCP首部长度）。该MSS值是为了告知对方最大的发送数据大小。</p><p>（2）当服务器端收到SYN报文后，会向请求端返回SYN+ACK（同步确认报文）报文，其中的“选项”字段也会有MSS值。</p><p>（3）通信双方选择SYN和SYN+ACK报文中最小的MSS最为此次TCP连接的MSS，从而达到通信双方协商MSS的效果。</p><p>因此，在第二次握手后就可以确定TCP中最大传输报文（MSS）大小。</p></blockquote><p>此后，每一次数据往返，cwnd就增大一倍（即每接收到一个ACK，cwnd就加1）这样，cwnd就迅速地向有效带宽靠拢。</p><p>包括HTTP在内的很多应用层协议都运行于TCP之上，无论带宽多大，每个TCP连接都必须经过慢启动阶段。我们不可能一上来就完全利用连接的最大带宽。</p><p>从一个较小的拥塞窗口开始，每次往返都令其翻倍。</p><p><img src="/2019/02/21/Web性能基础/1552728644844.png" alt="1552728644844"></p><p>假设：</p><ul><li>客户端和服务器的接收窗口为65535字节（64KB）</li><li>初始拥塞窗口：4段</li><li>往返时间为56ms。</li></ul><p>要达到64KB的吞吐量，需要把拥塞窗口大小增加到45个段，而这需要224ms：</p><p><img src="/2019/02/21/Web性能基础/1552731475351.png" alt="1552731475351"></p><p><img src="/2019/02/21/Web性能基础/1552731607667.png" alt="1552731607667"></p><p>三次握手和慢启动对简单HTTP传输的影响示例：</p><p>假设：</p><ul><li>往返时间：56ms</li><li>客户端到服务器的带宽：5Mbit/s</li><li>客户端和服务器接收窗口：65535字节</li><li>初始拥塞窗口：4段（4×1460字节=5.7KB）</li><li>服务器生成响应的处理时间：40ms</li><li>没有分组丢失、每个分组都要确认、GET请求只占1段。</li></ul><p><img src="/2019/02/21/Web性能基础/1552732025454.png" alt="1552732025454"></p><p>时间分析：</p><ul><li>0ms：客户端发送SYN开始TCP握手</li><li>28ms：服务器响应SYN-ACK并指定rwnd大小</li><li>56ms：客户端确认ACK，并指定rwnd大小，并立即发送GET请求</li><li>84ms：服务器收到GET</li><li>124ms：服务器生成20KB的响应，并发送4个TCP段，然后等待ACK</li><li>152ms：客户端收到4个段，并发送4个ACK</li><li>180ms：服务器针对每个ACK递增cwnd，然后发送8个TCP段</li><li>208ms：客户端收到8个段，并发送8个ACK</li><li>236ms：服务器针对每个ACK递增cwnd，然后发送剩余的TCP段</li><li>264ms：客户端收到剩余的TCP段，并发送ACK</li></ul><p>通过新TCP连接，在往返时间为56ms的两端之间传输一个20KB的文件需要264ms。</p><p>现在重用同一个TCP连接，再发一次相同的请求</p><p><img src="/2019/02/21/Web性能基础/1552732840016.png" alt="1552732840016"></p><p>时间分析：</p><ul><li>0ms：客户端发送GET</li><li>28ms：服务器收到GET</li><li>68ms：服务器生成20KB的响应，此时cwnd已经大于发送文件所需的15段了，因此一次性发送所有数据段</li><li>96ms：客户端收到所有15个段，分别发送ACK</li></ul><p>同一个连接、同样的请求，但没有三次握手和慢启动，只花了96ms，性能提升幅度达275%。</p><p>以上两种情况下，服务器和客户端之间的5Mbit/s的带宽并没有影响，因为拥塞窗口还远没有达到带宽大小。</p><p>增大TCP的初始拥塞窗口，把服务器的初始cwnd增大到RFC6928新规定的10段（IW10），是提升用户体验以及所有TCP应用性能的最简单方式。</p><p>Linux 2.6.29以上版本内核的新默认值就是IW10。</p><h4><span id="拥塞预防">拥塞预防</span></h4><p>慢启动以保守的窗口初始化连接，随后每次往返都会成倍提高传输的数据量，直到超过接收端的流量控制窗口，即系统配置的拥塞阈值（ssthresh）窗口，或者有分组丢失为止，此时拥塞预防算法介入。</p><p>拥塞预防算法把丢包作为网络拥塞的标志，即路径中某个连接或路由器拥堵了，以至于必须采取删包措施，调整窗口大小，以避免造成更多的包丢失，从而保证网络畅通。</p><p>重置拥塞窗口后，拥塞预防机制按照自己的算法来增大窗口以尽量避免继续丢包。某个时刻，可能又会有丢包，于是这个过程再从头开始。此时的TCP连接吞吐量跟踪曲线成锯齿状，这是拥塞控制和预防算法在处理丢包问题的体现。</p><p>丢包恢复算法：</p><ul><li>AIMD<sup>Multiplicative Decrease and Additive Increase，倍减加增</sup>：发生丢包时，先将拥塞窗口减半，然后每次往返再缓慢地给仓库增加一个固定的值。太过保守。</li><li>PRR<sup>Proportional Rate Reduction，比例减速</sup>：RFC6937规定的一个新算法，其目标就是改进丢包后的恢复速度。是Linux 3.2+内核默认的拥塞预防算法。</li></ul><h4><span id="带宽延迟积">带宽延迟积</span></h4><p>BDP<sup>Bandwidth-delay product</sup>：任意时刻处于在途未确认状态的最大数据量。</p><p>假设cwnd和rwnd的最小值为16KB，往返时间为100ms：</p><p><img src="/2019/02/21/Web性能基础/1552741208611.png" alt="1552741208611"></p><p>不管发送端和接收端的实际带宽多大，这个TCP连接的数据传输速率不会超过1.31Mbit/s。</p><p>假设往返时间不变，发送端的可用带宽为10Mbit/s，接收端为100Mbit/s。两端之间没有网络拥塞，我们的目标是充分利用客户端的10Mbit/s带宽：</p><p><img src="/2019/02/21/Web性能基础/1552741381486.png" alt="1552741381486"></p><p>窗口至少需要122.1KB才能充分利用10Mbit/s带宽。</p><h4><span id="队首阻塞">队首阻塞</span></h4><h4><span id="针对tcp的优化建议">针对TCP的优化建议</span></h4><h4><span id="性能检查清单">性能检查清单</span></h4><ul><li>把服务器内核升级到最新版本</li><li>确保cwnd大小为10</li><li>禁用空闲后的慢启动</li><li>确保启动窗口缩放</li><li>减少传输冗余数据</li><li>压缩要传输的数据</li><li>把服务器放到离用户近的地方以减少往返时间</li><li>尽最大可能重用已经建立的TCP连接</li></ul><h2><span id="udp">UDP</span></h2><h2><span id="tls">TLS</span></h2><h1><span id="无线网络性能">无线网络性能</span></h1><h2><span id="wifi">WIFI</span></h2><h2><span id="移动网络">移动网络</span></h2><h1><span id="http">HTTP</span></h1><h2><span id="http-1x">HTTP 1.x</span></h2><h2><span id="http-20">HTTP 2.0</span></h2><h2><span id="优化应用的交付">优化应用的交付</span></h2><h1><span id="浏览器api与协议">浏览器API与协议</span></h1><h2><span id="xmlhttprequest">XMLHttpRequest</span></h2><h2><span id="服务器发送事件">服务器发送事件</span></h2><h2><span id="websocket">websocket</span></h2><p>WebSocket可以实现客户端与服务器间同时双向、基于消息的文本或二进制数据传输。<br>WebSocket使得浏览器具备了实时、双向通信的能力，是由HTML5开始提供的一种浏览器与服务器进行全双工通讯的网络技术，属于应用层协议。基于TCP传输协议，并复用HTTP的握手通道。</p><ul><li>优点：<ul><li>支持双向通信，实时性更强</li><li>更好的支持二进制</li><li>较少的控制开销。连接创建后，ws客户端、服务的进行数据交换时，协议控制的数据包头部较小。</li><li>支持扩展。可以扩展协议，实现自定义的自协议（如自定义压缩算法等）</li></ul></li></ul><h3><span id="1-入门例子">1. 入门例子：</span></h3><ul><li>1.1 <strong>服务端</strong></li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> app = <span class="built_in">require</span>(<span class="string">'express'</span>)();</span><br><span class="line"><span class="keyword">var</span> server = <span class="built_in">require</span>(<span class="string">'http'</span>).Server(app);</span><br><span class="line"><span class="keyword">var</span> WebSocket = <span class="built_in">require</span>(<span class="string">'ws'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> wss = <span class="keyword">new</span> WebSocket.Server(&#123; <span class="attr">port</span>: <span class="number">8080</span> &#125;);</span><br><span class="line"></span><br><span class="line">wss.on(<span class="string">'connection'</span>, <span class="function"><span class="keyword">function</span> <span class="title">connection</span>(<span class="params">ws</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'server: receive connection.'</span>);</span><br><span class="line">    </span><br><span class="line">    ws.on(<span class="string">'message'</span>, <span class="function"><span class="keyword">function</span> <span class="title">incoming</span>(<span class="params">message</span>) </span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'server: received %s'</span>, message);</span><br><span class="line">        ws.send(<span class="string">'server: reply'</span>);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    ws.on(<span class="string">'pong'</span>, () =&gt; &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'server: received pong from client'</span>);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    ws.send(<span class="string">'world'</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// setInterval(() =&gt; &#123;</span></span><br><span class="line">    <span class="comment">//     ws.ping('', false, true);</span></span><br><span class="line">    <span class="comment">// &#125;, 2000);</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.sendfile(__dirname + <span class="string">'/index.html'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>);</span><br></pre></td></tr></table></figure><ul><li>1.2 <strong>客户端</strong></li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">  <span class="keyword">var</span> ws = <span class="keyword">new</span> WebSocket(<span class="string">'ws://localhost:8080'</span>);</span><br><span class="line">  ws.onopen = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'ws onopen'</span>);</span><br><span class="line">    ws.send(<span class="string">'from client: hello'</span>);</span><br><span class="line">  &#125;;</span><br><span class="line">  ws.onmessage = <span class="function"><span class="keyword">function</span> (<span class="params">e</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'ws onmessage'</span>);</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'from server: '</span> + e.data);</span><br><span class="line">  &#125;;</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><ul><li>1.3 <strong>运行结果</strong></li></ul><p><em>服务端输出</em>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server: receive connection.</span><br><span class="line">server: received hello</span><br></pre></td></tr></table></figure></p><p><em>客户端输出</em>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">client: ws connection is open</span><br><span class="line">client: received world</span><br></pre></td></tr></table></figure></p><h3><span id="2-如何建立连接">2. 如何建立连接</span></h3><p>WebSocket复用了HTTP的握手通道。具体是指，客户端通过HTTP请求与WebSocket服务器协商升级协议。</p><ul><li><p>2.1. 客户端：申请协议升级</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: localhost:8080</span><br><span class="line">Origin: http://127.0.0.1:3000</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Sec-WebSocket-Version: 13</span><br><span class="line">Sec-WebSocket-Key: w4v7O6xFTi36lq3RNcgctw==</span><br></pre></td></tr></table></figure></li><li><p>2.2. 服务端：响应协议升级</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 101 Switching Protocols</span><br><span class="line">Connection:Upgrade</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Sec-WebSocket-Accept: Oy4NRAQ13jhfONC7bP8dTKb4PTU=</span><br></pre></td></tr></table></figure></li><li><p>2.3. Sec-WebSocket-Accept的计算</p></li></ul><p>伪代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;toBase64( sha1( Sec-WebSocket-Key +258EAFA5-E914-47DA-95CA-C5AB0DC85B11 )  )</span><br></pre></td></tr></table></figure></p><h3><span id="3-数据帧格式">3. 数据帧格式</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> 0                   1                   2                   3</span><br><span class="line"> 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1</span><br><span class="line">+-+-+-+-+-------+-+-------------+-------------------------------+</span><br><span class="line">|F|R|R|R| opcode|M| Payload len |    Extended payload length    |</span><br><span class="line">|I|S|S|S|  (4)  |A|     (7)     |             (16/64)           |</span><br><span class="line">|N|V|V|V|       |S|             |   (if payload len==126/127)   |</span><br><span class="line">| |1|2|3|       |K|             |                               |</span><br><span class="line">+-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +</span><br><span class="line">|     Extended payload length continued, if payload len == 127  |</span><br><span class="line">+ - - - - - - - - - - - - - - - +-------------------------------+</span><br><span class="line">|                               |Masking-key, if MASK set to 1  |</span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line">| Masking-key (continued)       |          Payload Data         |</span><br><span class="line">+-------------------------------- - - - - - - - - - - - - - - - +</span><br><span class="line">:                     Payload Data continued ...                :</span><br><span class="line">+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +</span><br><span class="line">|                     Payload Data continued ...                |</span><br><span class="line">+---------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h3><span id="4-数据传递">4. 数据传递</span></h3><p>使用场景及性能</p><h2><span id="webrtc">WebRTC</span></h2>]]></content>
    
    <summary type="html">
    
      有关于Web性能的基础知识
    
    </summary>
    
    
      <category term="Web" scheme="http://yoursite.com/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>Linux性能优化之CPU篇</title>
    <link href="http://yoursite.com/2019/02/20/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BCPU%E7%AF%87/"/>
    <id>http://yoursite.com/2019/02/20/Linux性能优化之CPU篇/</id>
    <published>2019-02-20T13:18:11.000Z</published>
    <updated>2019-03-12T08:39:18.531Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#平均负载">平均负载</a></li><li><a href="#上下文切换">上下文切换</a><ul><li><a href="#概述">概述</a></li><li><a href="#怎么查看系统的上下文切换情况">怎么查看系统的上下文切换情况</a></li></ul></li><li><a href="#cpu的使用率">CPU的使用率</a><ul><li><a href="#概述-1">概述</a></li><li><a href="#查看cpu使用率">查看CPU使用率</a></li><li><a href="#cpu使用率过高怎么办">CPU使用率过高怎么办？</a></li></ul></li><li><a href="#不可中断进程和僵尸进程的处理方法">不可中断进程和僵尸进程的处理方法</a><ul><li><a href="#进程状态">进程状态</a></li><li><a href="#处理方法">处理方法</a></li></ul></li><li><a href="#软中断">软中断</a><ul><li><a href="#怎么查看软中断和内核线程呢">怎么查看软中断和内核线程呢？</a></li></ul></li><li><a href="#如何迅速分析出系统cpu的瓶颈在哪里">如何迅速分析出系统CPU的瓶颈在哪里？</a></li><li><a href="#cpu性能优化的几个思路">CPU性能优化的几个思路</a><ul><li><a href="#性能优化方法论">性能优化方法论</a><ul><li><a href="#怎么评估性能优化的效果">怎么评估性能优化的效果？</a></li><li><a href="#多个性能问题同时存在要怎么选择">多个性能问题同时存在，要怎么选择？</a></li><li><a href="#有多种优化方法时要如何选择">有多种优化方法时，要如何选择？</a></li></ul></li><li><a href="#cpu优化">CPU优化</a><ul><li><a href="#应用程序优化">应用程序优化</a></li><li><a href="#系统优化">系统优化</a></li></ul></li><li><a href="#不要过早优化">不要过早优化</a></li></ul></li></ul><!-- tocstop --><h2><span id="平均负载">平均负载</span></h2><p>什么是平均负载？</p><p>是指一定时间内系统中处于可运行状态和不可中断等待状态的进程数的平均数</p><h2><span id="上下文切换">上下文切换</span></h2><h3><span id="概述">概述</span></h3><p>进程在竞争CPU的时候并没有真正运行，为什么还会导致系统的负载升高呢？这是因为CPU上下文切换。</p><p>在每个任务运行前，CPU都需要知道任务从哪里加载，又从哪里开始运行，需要系统事先帮它设置好CPU寄存器和程序计数器（Program Counter，PC）。</p><p>CPU寄存器，是CPU内置的容量小，但速度极快的内存。而程序计数器，则是用来存储CPU正在执行的指令位置、或者即将执行的下一条指令位置。它们都是CPU在运行任何任务前，必须的依赖环境，因此也被叫做CPU上下文。如下图所示：</p><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551593332821.png" alt="1551593332821"></p><p>CPU上下文切换就是先把前一个任务的CPU上下文保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。</p><p>根据任务的不同，CPU的上下文切换可以分为：</p><ul><li><p>进程上下文切换</p><p>Linux按照特权等级，把进程的运行空间分为内核空间和用户空间，对应的特权等级分别为Ring 0和Ring 3。</p><ul><li><p>内核空间（Ring 0）具有最高权限，可以直接访问所有资源；</p></li><li><p>用户空间（Ring 3）只能访问受限资源，不能访问内存等硬件设备，必须通过系统调用进入到内核中，才能访问这些特权资源。</p><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551594532880.png" alt="1551594532880"></p></li></ul><p>对于一个进程，从用户态到内核态的转变，需要通过系统调用来完成。一次系统调用的过程，会发生两次CPU上下文切换。</p><p>进程的上下文切换：进程是由内核来管理和调度的，进程的切换只能发生再内核态。进程的上下文不仅包括虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。</p><p>因此，进程的上下文切换比系统调用时多了一步：在保存当前进程的内核状态和CPU寄存器之前，需要先把该进程的虚拟内存、栈保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。</p><p>在进程上下文切换次数较多的情况下，很容易导致CPU将大量实际耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。</p><p>另外，Linux通过TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB也需要更新，内存的访问也会随之变慢。</p></li><li><p>线程上下文切换</p><p>线程是调度的基本单位，而进程是资源拥有的基本单位。</p><p>所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。</p><p>所以，对于线程和进程，我们可以这样理解：</p><ul><li>当进程只有一个线程时，可以认为进程就等于线程；</li><li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。</li><li>线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时是需要保存的</li></ul></li><li><p>中断上下文切换</p><p>为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。</p><p>跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。</p><p>中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括CPU寄存器、内核堆栈、硬件中断参数等。</p><p>对同一个CPU来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。</p></li></ul><h3><span id="怎么查看系统的上下文切换情况">怎么查看系统的上下文切换情况</span></h3><ol><li>使用vmstat</li></ol><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551598709362.png" alt="1551598709362"></p><ul><li>cs（context switch）是每秒上下文切换的次数</li><li>in（interrupt）是每秒中断的次数</li><li>r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待CPU的进程数</li><li>b（Blocked）则是处于不可中断睡眠状态的进程数</li></ul><ol start="2"><li>对于每个进程的详细情况，可使用pidstat</li></ol><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551599003703.png" alt="1551599003703"></p><p>其中：</p><ul><li>cswch，表示每秒自愿上下文切换（voluntary context switches）的次数</li><li>nvcswch，表示每秒非自愿上下文切换（non  voluntary context switches）的次数。</li></ul><p>这两个概念意味着不同的性能问题：</p><ul><li>自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说，I/O、内存等系统资源不足时，就会发生自愿上下文切换。</li><li>非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生上下文切换。比如说，大量进程都在争抢CPU时，就容易发生非自愿上下文切换。</li></ul><h2><span id="cpu的使用率">CPU的使用率</span></h2><h3><span id="概述">概述</span></h3><p>Linux是多任务操作系统，它将CPU时间划分为时间片，然后通过调度算法轮流分配给各个任务使用。</p><blockquote><p>调度算法：</p><p>Linux的调度算法一直在更新，最新的调度算法是CFS（完全公平调度器）。</p><p>调度算法决定在众多的线程中哪个线程获得执行、什么时候开始执行、执行多久。</p><p>调度器先划分出Scheduler Classes<sup>调度类</sup>，每个不同的Class对应不同类型的线程，每个Class都有自己的优先级。</p><p>调度管理基础代码会遍历在内核中注册了的调度类，选择高优先级的调度类，然后让此调度类按照自己的调度算法选择下一个执行的线程。</p><p>常用的调度类：</p><ul><li><p>SCHED_NORMAL  普通线程调度类</p><p>只具有nice值，映射到用户层的取值范围为-20-19</p><p>调度器要解决一个基本问题是：要先找出‘交互线程’，保证这种线程优先得到调度，然后才考虑其他问题。</p></li><li><p>SCHED_FIFO </p><p>SCHED_RR</p><p>实时线程调度类</p><p>拥有实时优先级（real-time priority）,默认取值为0-99</p></li></ul></blockquote><p>为了维护CPU时间，Linux通过事先定义的节拍率（内核中表示为HZ，表示每秒触发的时间中断的次数），触发时间中断，并使用全局变量Jiffies记录了开机以来的节拍数。每发生一次时间中断，Jiffies的值就加1。</p><p>节拍率HZ是内核的可配选项，可以设置为100、250、1000等。可以通过以下命令查看它的配置值：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@geek ~]<span class="comment"># grep -i "config_hz" /boot/config-$(uname -r)</span></span><br><span class="line"><span class="comment"># CONFIG_HZ_PERIODIC is not set</span></span><br><span class="line"><span class="comment"># CONFIG_HZ_100 is not set</span></span><br><span class="line"><span class="comment"># CONFIG_HZ_250 is not set</span></span><br><span class="line"><span class="comment"># CONFIG_HZ_300 is not set</span></span><br><span class="line">CONFIG_HZ_1000=y</span><br><span class="line">CONFIG_HZ=1000</span><br></pre></td></tr></table></figure><p>内核提供了一个用户空间节拍率USER_HZ，它总是固定为100，也就是说，在用户空间一个节拍的时间为1/100秒。</p><p>/proc/stat提供了系统CPU和任务统计信息。执行以下命令，可以看到CPU的相关信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@geek ~]# cat /proc/stat | grep ^cpu</span><br><span class="line">cpu  126633 3769 165166 11498685 3763 0 21088 0 0 0</span><br><span class="line">cpu0 126633 3769 165166 11498685 3763 0 21088 0 0 0</span><br></pre></td></tr></table></figure><p>第一列表示的是CPU编号，第一行没有编号的CPU，表示的是所有CPU的累加。</p><p>其他列表示不同场景下CPU的累加节拍数，单位是1/USER_HZ秒，也就是10ms（1/100秒），其实也就是不同场景下的CPU时间。</p><p>后面的列依照顺序，分别为<sup>括号中内容表示缩写</sup>：</p><ul><li>user（us），代表用户态CPU时间，注意它不包括下面的nice时间，但包括了guest时间。</li><li>nice（ni），代表低优先级用户态CPU时间，也就是进程的nice值被调整为1-19之间的CPU时间。</li><li>system（sys），代表内核态CPU时间。</li><li>idle（id），代表空闲时间。注意，它不包括等待I/O的时间（iowait）</li><li>iowait（wa），代表等待I/O的CPU时间。</li><li>irq（hi），代表处理硬中断的CPU时间。</li><li>softirq（si），代表处理软中断的CPU时间。</li><li>steal（st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的CPU时间。</li><li>guest（guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的CPU时间。</li><li>guest_nice（gnice），代表以低优先级运行的虚拟机时间。</li></ul><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551432942707.png" alt="1551432942707"></p><p>为了计算CPU的使用率，性能工具一般都会取间隔一段时间（比如3秒）的两次值，做差后，在计算出这段时间内的平均CPU使用率，即：</p><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551433018852.png" alt="1551433018852"></p><p>跟系统的指标类似，Linux也给每个进程提供了运行情况的统计信息，也就是/proc/[pid]/stat。</p><p>那是不是说要查看CPU使用率，就必须先读取/proc/stat和/proc/[pid]/stat这两个文件，然后再按照上面的公式计算出来呢？</p><p>当然不是，各种各样的性能分析工具已经帮我们计算好了。</p><p>需要注意的是，性能分析工具给出的都是间隔一段时间的平均CPU使用率，所以要注意间隔时间的设置，特别是用多个工具对比分析时，一定要保证它们用的是相同的时间间隔。</p><p>top默认使用3秒时间间隔，而ps使用的是进程的整个生命周期，所以这两个工具报告的CPU使用率，默认的结果很可能是不一样的。</p><h3><span id="查看cpu使用率">查看CPU使用率</span></h3><p>使用top命令，如下：</p><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551436121518.png" alt="1551436121518"></p><p>对于进程的实时信息，每个进程都有一个%CPU列，表示进程的CPU使用率。它是用户态和内核态CPU使用率的总和，包括进程用户空间使用的CPU、提供系统调用执行的内核空间CPU、以及在就绪队列等待运行的CPU。在虚拟化环境中，它还包括了运行虚拟机占用的CPU。</p><p>所以，top并没有细分进程的用户态CPU和内核态CPU。那要怎么查看每个进程的详细情况呢？可以使用pidstat，是一个专门分析每个进程CPU使用情况的工具。</p><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551436602236.png" alt="1551436602236"></p><p>上面的pidstat命令，间隔1s展示了进程的3组CPU使用率，包括：</p><ul><li>用户态CPU使用率（%usr）</li><li>内核态CPU使用率（%system）</li><li>运行虚拟机CPU使用率（%guest）</li><li>以及总的CPU使用率（%CPU）</li></ul><h3><span id="cpu使用率过高怎么办">CPU使用率过高怎么办？</span></h3><p>通过top、ps、pidstat等工具，能够轻松找到CPU使用率较高的进程。接下来，占用CPU的到底是代码中的哪个函数呢？找到它，才能高效有针对性的进行优化。</p><p>怎么找呢？用GDB？GDB是个功能强大的程序调试利器。但它并不适合在性能分析的早期使用。为什么呢？因为GDB调试程序的过程会中断程序运行，这在线上环境往往是不允许的。所以，GDB只适合在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。</p><p>哪种工具适合在第一时间分析进程的CPU问题呢？推荐使用perf。</p><p>perf是Linux2.6.31以后内置的性能分析工具。它以性能数据采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。</p><ul><li><p>perf top</p><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551437842824.png" alt="1551437842824"></p><p>输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数（Event count）。比如以上例子中，perf总共采集了25k个CPU时钟事件，而总事件数则是262083270。</p><p>再往下看，每一行包含四列，分别是：</p><ul><li>第一列Overhead，是该符号的性能事件所在所有采样中的比例</li><li>第二列Shared Object，是该函数或指令所在的动态共享对象（Dynamic Shared Object),如内核、进程名、动态链接库名、内核模块名等</li><li>第三列，是动态共享对象的类型。比如：[.]表示用户空间的可执行程序、或者动态链接库，而[k]表示内核空间</li><li>最后一列Symbol是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。</li></ul></li><li><p>perf record &amp; perf report</p><p>使用perf record保持数据，保存后的数据，需要使用perf record解析展示。</p><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551439032460.png" alt="1551439032460"></p></li></ul><h2><span id="不可中断进程和僵尸进程的处理方法">不可中断进程和僵尸进程的处理方法</span></h2><h3><span id="进程状态">进程状态</span></h3><p>top或ps命令输出中，进程状态栏各符号的含义：</p><ul><li><p>R</p><p>Running或Runnable的缩写，表示进程在CPU的就绪队列中，正在运行或者正在等待运行</p></li><li><p>D</p><p>Disk Sleep的缩写，也就是不可中断睡眠，一般表示进程正在和硬件交互，并且交互过程不允许被其他进程或中断打断</p></li><li><p>Z</p><p>Zombie的缩写，表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID等）</p></li><li><p>S</p><p>Interruptible Sleep的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入R状态。</p></li><li><p>I</p><p>Idle的缩写。也就是空闲状态，用在不可中断睡眠的内核进程上。</p></li><li><p>T或者t</p><p>Stopped或Traced的缩写，表示进程处于暂停或跟踪状态。</p><p>向一个进程发送SIGSTOP信号，它就会响应这个信号变成Stopped，再向它发送SIGCONT信号，进程又会恢复运行。</p><p>当你用调试器调试一个进程时，在使用断点中断进程后，进程就会变成跟踪状态，这其实是一种特殊的暂停状态，只不过你可以用调试器来跟踪并按需要控制进程的运行。</p></li><li><p>X</p><p>Dead的意思。表示进程已经消亡，所以你不会在top或者ps命令输出中看到它。</p></li></ul><p><img src="/2019/02/20/Linux性能优化之CPU篇/1551502558996.png" alt="1551502558996"></p><ul><li><p>s</p><p>session leader的意思。什么是session呢？session指的是相互关联的进程组。</p></li><li><p>+</p><p>表示的是前台进程</p></li></ul><h3><span id="处理方法">处理方法</span></h3><p>出现僵尸进程，是由于父进程没有回收子进程的资源。所以，要找到僵尸进程的父进程，在父进程里解决。</p><p>使用pstree命令，找到父进程。</p><h2><span id="软中断">软中断</span></h2><p>中断是一种异步的事件处理机制，可以提高系统的并发处理能力。</p><p>由于中断处理程序会打断其他进程的运行，所以，为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。</p><p>为了解决中断处理程序执行过长和中断丢失的问题，Linux将中断处理过程分成了两个阶段：</p><ul><li><p>上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作；</p><p>直接处理硬件请求，硬中断，特点是快速执行</p><p>会打断CPU正在执行的任务，然后立即执行中断处理程序</p></li><li><p>下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。</p><p>由内核触发，软中断，特点是延迟执行</p><p>以内核线程的方式执行，每个CPU都对应一个软中断内核线程，名为“ksoftirqd/CPU编号”</p></li></ul><p>软中断不只包括硬件设备中断处理程序的下半部，一些内核自定义的事件也属于软中断，比如内核调度和RCU锁（Read-Copy Update）</p><h3><span id="怎么查看软中断和内核线程呢">怎么查看软中断和内核线程呢？</span></h3><p>/proc/softirqs</p><p>/proc/interrupts</p><h2><span id="如何迅速分析出系统cpu的瓶颈在哪里">如何迅速分析出系统CPU的瓶颈在哪里？</span></h2><h2><span id="cpu性能优化的几个思路">CPU性能优化的几个思路</span></h2><p>在找到CPU的性能瓶颈之后，下一步要做的就是优化了，也就是找出充分利用CPU的方法，以便完成更多的工作。</p><h3><span id="性能优化方法论">性能优化方法论</span></h3><p>在经过千辛万苦，通过各种性能优化方法，终于找到引发性能问题的瓶颈后，是不是立即就要开始优化了呢？</p><p>此时，不必着急，动手之前，可以先看看下面三个问题：</p><ul><li>要怎么判断优化措施是否是有效的？特别是，优化后性能到底又提升了多少呢？</li><li>性能问题通常不是独立的，如果有多个性能问题同时发生，应该先优化哪一个呢？</li><li>提升性能的方法并不是唯一的，当有多种方法可以选择时，选用哪一种呢？是不是总选那个最大程度提升性能的方法就行了呢？</li></ul><p>如果你可以轻松回答这三个问题，那么优化可以立即开始了。</p><h4><span id="怎么评估性能优化的效果">怎么评估性能优化的效果？</span></h4><p>为了评估效果，我们需要对系统的性能指标进行量化，并且要分别测试出优化前、后的性能指标，用前后指标的变化来对比呈现效果。</p><p>性能评估“三步走”：</p><ul><li>确定性能的量化指标</li><li>测试优化前的性能指标</li><li>测试优化后的性能指标</li></ul><h4><span id="多个性能问题同时存在要怎么选择">多个性能问题同时存在，要怎么选择？</span></h4><p><strong>并不是所有的性能问题都值得优化</strong>。</p><p>80%的问题都是由20%的代码导致的。只要找出这20%的位置，你就可以优化80%的性能。</p><h4><span id="有多种优化方法时要如何选择">有多种优化方法时，要如何选择？</span></h4><p>一般情况下，选能最大提升性能的方法，这也是性能优化的目标。</p><p>但是，性能优化并非没有成本。性能优化通常会带来复杂度的提升，降低程序的可维护性，还可能在优化一个指标时，引发其他指标的异常。</p><p>所以，在考虑选哪个性能优化方法时，需要综合多方面的因素。</p><h3><span id="cpu优化">CPU优化</span></h3><p>在清楚了性能优化最基本的三个问题后，接下来从应用程序和系统的角度，分别来看看如何才能降低CPU使用率，提高CPU的并行处理能力：</p><h4><span id="应用程序优化">应用程序优化</span></h4><p>从应用程序的角度来说，降低CPU使用率的最好方法是，排除所有不必要的工作，只保留最核心的逻辑。比如减少循环的层次、减少递归、减少动态内存分配等等。</p><p>此外，还有：</p><ul><li>编译器优化：很多编译器都会提供优化选项，适当开启它们，在编译阶段你就可以获得编译器的帮助，来提升性能。比如，gcc就提供了优化选项-O2，开启后会自动对应用程序的代码进行优化。</li><li>算法优化：使用复杂度更低的算法，可以显著加快处理速度。比如，在数据比较大的情况下，可以用O(nlogn)的排序算法（如快排、归并排序等）代替O(n^2)的排序算法（如冒泡、插入排序等）</li><li>异步处理：使用异步处理，可以避免程序因为等待某个资源而一直阻塞，从而提升程序的并发处理能力。比如，把轮询替换为事件通知，就可以避免轮询耗费CPU的问题</li><li>多线程代替多进程：相对于进程的上下文切换，线程的上下文切换并不切换进程地址空间，因此可以降低上下文切换的成本。</li><li>善用缓存：经常访问的数据或计算过程中的步骤，可以放到内存中缓存起来，只要在下次要用的时候就直接从内存中获取，加快程序的处理速度。</li></ul><h4><span id="系统优化">系统优化</span></h4><p>从系统的角度来说，优化CPU的运行，一方面要充分利用CPU缓存的本地性，加速缓存访问；另一方面，就要控制进程的CPU使用情况，减少进程间的相互影响。</p><ul><li>CPU绑定：把进程绑定到一个或者多个CPU上，可以提高CPU缓存的命中率，减少跨CPU调度带来的上下文切换问题</li><li>CPU独占：跟CPU绑定类似，进一步将CPU分组，并通过CPU亲和性机制为其分配进程。这样，这些CPU就由指定的进程独占，也就是说，不允许其他进程再来使用这些CPU</li><li>优先级调整：使用nice调整进程的优先级，正值调低优先级，负值调高优先级。</li><li>为进程设置资源限制：使用Linux cgroups来设置进程的CPU使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源</li><li>NUMA优化：支持NUMA的处理器会被划分为多个node，每个node都有自己的本地内存空间。NUMA优化，其实就是让CPU尽可能只访问本地内存</li><li>中断负载均衡：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的CPU。开启irqbalance服务或者配置smp_affinity，就可以把中断处理过程自动负载均衡到多个CPU上。</li></ul><h3><span id="不要过早优化">不要过早优化</span></h3><blockquote><p>过早优化是万恶之源。——高纳德</p></blockquote><p>过早优化不可取。这是因为：</p><ul><li>优化会带来复杂性的提升，降低可维护性；</li><li>需求不是一成不变的。针对当前情况进行的优化，很可能并不适应快速变化的新需求。这样，在新需求出现时，这些复杂的优化，反而可能阻碍新功能的开发。</li></ul><p>所以，性能优化最好是逐步完善，动态进行的，不追求一步到位，<strong>而要首先保证能满足当前的性能要求</strong>。当发现性能不满足要求或者出现性能瓶颈时，再根据性能评估的结果，选择最重要的性能问题进行优化。</p>]]></content>
    
    <summary type="html">
    
      如何做Linux的性能优化
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
</feed>
